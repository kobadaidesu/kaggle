{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Fold-Safeç‰ˆ (å®Œå…¨ç‰ˆ)\n",
    "\n",
    "## ğŸ¯ æ”¹å–„ç‚¹:\n",
    "- âœ… **Fold-Safeå‰å‡¦ç†**: å„Foldã§çµ±è¨ˆé‡ã‚’å†è¨ˆç®—\n",
    "- âœ… **GroupKFold**: Ticketã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–\n",
    "- âœ… **Is_Marriedä¿®æ­£**: Titleçµ±åˆå‰ã«åˆ¤å®š\n",
    "- âœ… **æœ€é©é–¾å€¤æ¢ç´¢**: OOFã§æœ€é©åŒ–\n",
    "- âœ… **ãƒ¡ã‚¿å­¦ç¿’**: é‡ã¿æœ€é©åŒ–\n",
    "- âœ… **CatBoostæœ€é©åŒ–**: æ–‡å­—åˆ—ã‚«ãƒ†ã‚´ãƒªä½¿ç”¨\n",
    "- âœ… **æ•°å€¤ç‰¹å¾´é‡**: Age, Fareã‚’é€£ç¶šå€¤ã§ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import string\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Target distribution:\n",
      "Perished\n",
      "1    0.616162\n",
      "0    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df_train['Perished'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. åŸºæœ¬ç‰¹å¾´é‡ä½œæˆï¼ˆFold-independentï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åŸºæœ¬ç‰¹å¾´é‡ä½œæˆå®Œäº†\n",
      "Train shape: (891, 20)\n",
      "Test shape: (418, 19)\n",
      "Is_Marriedæœ‰åŠ¹æ•°: 125ä»¶\n"
     ]
    }
   ],
   "source": [
    "def extract_surname(data):\n",
    "    \"\"\"åå‰ã‹ã‚‰å§“ã‚’æŠ½å‡º\"\"\"\n",
    "    families = []\n",
    "    for i in range(len(data)):\n",
    "        name = data.iloc[i]\n",
    "        if '(' in name:\n",
    "            name_no_bracket = name.split('(')[0]\n",
    "        else:\n",
    "            name_no_bracket = name\n",
    "        family = name_no_bracket.split(',')[0]\n",
    "        for c in string.punctuation:\n",
    "            family = family.replace(c, '').strip()\n",
    "        families.append(family)\n",
    "    return families\n",
    "\n",
    "\n",
    "def create_base_features(df):\n",
    "    \"\"\"\n",
    "    Fold-independentãªåŸºæœ¬ç‰¹å¾´é‡ã®ã¿ä½œæˆ\n",
    "    çµ±è¨ˆé‡ã‚’ä½¿ã†ç‰¹å¾´é‡ã¯Foldå†…ã§ä½œæˆã™ã‚‹\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. TitleæŠ½å‡ºï¼ˆç”Ÿã®ã¾ã¾ä¿æŒï¼‰\n",
    "    data['Title_raw'] = data['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "    \n",
    "    # 2. Is_Marriedï¼ˆTitleçµ±åˆå‰ã«åˆ¤å®šï¼‰\n",
    "    data['Is_Married'] = (data['Title_raw'] == 'Mrs').astype(int)\n",
    "    \n",
    "    # 3. Titleæ­£è¦åŒ–\n",
    "    data['Title'] = data['Title_raw'].replace(\n",
    "        ['Miss', 'Mrs', 'Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms'\n",
    "    )\n",
    "    data['Title'] = data['Title'].replace(\n",
    "        ['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy'\n",
    "    )\n",
    "    \n",
    "    # 4. Familyï¼ˆå§“ï¼‰\n",
    "    data['Family'] = extract_surname(data['Name'])\n",
    "    \n",
    "    # 5. Family_Size\n",
    "    data['Family_Size'] = data['SibSp'] + data['Parch'] + 1\n",
    "    \n",
    "    # 6. Family_Size_Grouped\n",
    "    family_map = {\n",
    "        1: 'Alone',\n",
    "        2: 'Small', 3: 'Small', 4: 'Small',\n",
    "        5: 'Medium', 6: 'Medium',\n",
    "        7: 'Large', 8: 'Large', 11: 'Large'\n",
    "    }\n",
    "    data['Family_Size_Grouped'] = data['Family_Size'].map(family_map)\n",
    "    \n",
    "    # 7. Deck\n",
    "    data['Deck'] = data['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
    "    data['Deck'] = data['Deck'].replace(['A', 'B', 'C'], 'ABC')\n",
    "    data['Deck'] = data['Deck'].replace(['D', 'E'], 'DE')\n",
    "    data['Deck'] = data['Deck'].replace(['F', 'G'], 'FG')\n",
    "    data['Deck'] = data['Deck'].replace(['T'], 'M')\n",
    "    \n",
    "    # 8. Embarkedè£œå®Œ\n",
    "    data['Embarked'] = data['Embarked'].fillna('S')\n",
    "    \n",
    "    # 9. Sex x Pclass äº¤äº’ä½œç”¨\n",
    "    data['Sex_Pclass'] = data['Sex'] + '_' + data['Pclass'].astype(str)\n",
    "    \n",
    "    # Age, Fareã¯å…ƒã®ã¾ã¾ä¿æŒï¼ˆFoldå†…ã§è£œå®Œã™ã‚‹ï¼‰\n",
    "    data['Age'] = pd.to_numeric(data['Age'], errors='coerce')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# åŸºæœ¬ç‰¹å¾´é‡ä½œæˆ\n",
    "train_base = create_base_features(df_train)\n",
    "test_base = create_base_features(df_test)\n",
    "\n",
    "print(f\"âœ… åŸºæœ¬ç‰¹å¾´é‡ä½œæˆå®Œäº†\")\n",
    "print(f\"Train shape: {train_base.shape}\")\n",
    "print(f\"Test shape: {test_base.shape}\")\n",
    "print(f\"Is_Marriedæœ‰åŠ¹æ•°: {train_base['Is_Married'].sum()}ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šå®Œäº†\n"
     ]
    }
   ],
   "source": [
    "best_params_randomforest = {\n",
    "    'n_estimators': 1200,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 6,\n",
    "    'min_samples_leaf': 3,\n",
    "    'max_features': 'sqrt',\n",
    "    'bootstrap': True,\n",
    "    'max_samples': 0.9,\n",
    "    'criterion': 'gini',\n",
    "    'class_weight': None,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "best_params_catboost = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 6.0,\n",
    "    'bagging_temperature': 0.5,\n",
    "    'random_strength': 1.0,\n",
    "    'rsm': 0.9,\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'Logloss',\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "best_params_xgboost = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 5,\n",
    "    'gamma': 0.3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.5,\n",
    "    'reg_lambda': 1.5,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'eval_metric': 'logloss',\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "print(\"ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šå®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fold-Safeå­¦ç¿’é–¢æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fold-Safeé–¢æ•°å®šç¾©å®Œäº†\n"
     ]
    }
   ],
   "source": [
    "def apply_fold_safe_features(train_data, valid_data, test_data, train_indices):\n",
    "    \"\"\"\n",
    "    ğŸ¯ Fold-Safe: å„Foldã®train setã®ã¿ã§çµ±è¨ˆé‡ã‚’è¨ˆç®—\n",
    "    \"\"\"\n",
    "    train_fold = train_data.iloc[train_indices].copy()\n",
    "    \n",
    "    # 1. Ticket_Frequencyï¼ˆFold trainã®ã¿ã§è¨ˆç®—ï¼‰\n",
    "    fold_ticket_map = train_fold.groupby('Ticket').size().to_dict()\n",
    "    \n",
    "    train_data['Ticket_Frequency'] = train_data['Ticket'].map(fold_ticket_map).fillna(1)\n",
    "    valid_data['Ticket_Frequency'] = valid_data['Ticket'].map(fold_ticket_map).fillna(1)\n",
    "    test_data['Ticket_Frequency'] = test_data['Ticket'].map(fold_ticket_map).fillna(1)\n",
    "    \n",
    "    # 2. Ageè£œå®Œï¼ˆFold trainã®ã¿ã®ä¸­å¤®å€¤ï¼‰\n",
    "    fold_age_median = train_fold.groupby(['Sex', 'Pclass'])['Age'].median()\n",
    "    \n",
    "    for data in [train_data, valid_data, test_data]:\n",
    "        for pclass in [1, 2, 3]:\n",
    "            for sex in ['male', 'female']:\n",
    "                mask = (data['Age'].isnull()) & (data['Pclass'] == pclass) & (data['Sex'] == sex)\n",
    "                if mask.any():\n",
    "                    data.loc[mask, 'Age'] = fold_age_median.loc[(sex, pclass)]\n",
    "    \n",
    "    # Age_Band\n",
    "    for data in [train_data, valid_data, test_data]:\n",
    "        data['Age_Band'] = pd.cut(data['Age'], bins=[0, 12, 18, 30, 50, 80], \n",
    "                                   labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "    \n",
    "    # 3. Fareè£œå®Œï¼ˆFold trainã®ã¿ã®çµ±è¨ˆé‡ï¼‰\n",
    "    fold_fare_median = train_fold['Fare'].median()\n",
    "    fold_fare_quantiles = train_fold['Fare'].quantile([0.25, 0.5, 0.75]).values\n",
    "    \n",
    "    for data in [train_data, valid_data, test_data]:\n",
    "        data['Fare'] = data['Fare'].fillna(fold_fare_median)\n",
    "        data['Fare_Band'] = pd.cut(\n",
    "            data['Fare'],\n",
    "            bins=[-np.inf] + fold_fare_quantiles.tolist() + [np.inf],\n",
    "            labels=['Low', 'Medium', 'High', 'Very_High']\n",
    "        )\n",
    "    \n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "\n",
    "def prepare_fold_data(train_data, valid_data, test_data, cat_features):\n",
    "    \"\"\"\n",
    "    Foldç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆRF/XGBç”¨ã¨CatBoostç”¨ï¼‰\n",
    "    \"\"\"\n",
    "    feature_cols = [\n",
    "         'Is_Married',\n",
    "        'Embarked', 'Title', 'Family_Size_Grouped', 'Ticket_Frequency', 'Deck',\n",
    "        'Age_Band', 'Fare_Band', 'Sex_Pclass'\n",
    "        # 'Age', 'Fare', 'Family_Size','Pclass',\n",
    "    ]\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º\n",
    "    X_train = train_data[feature_cols].copy()\n",
    "    y_train = train_data['Perished'].copy()\n",
    "    X_valid = valid_data[feature_cols].copy()\n",
    "    y_valid = valid_data['Perished'].copy()\n",
    "    X_test = test_data[feature_cols].copy()\n",
    "    \n",
    "    # CatBoostç”¨ï¼ˆæ–‡å­—åˆ—ã®ã¾ã¾ï¼‰\n",
    "    X_train_cat = X_train.copy()\n",
    "    X_valid_cat = X_valid.copy()\n",
    "    X_test_cat = X_test.copy()\n",
    "    \n",
    "    # RF/XGBç”¨ï¼ˆLabelEncoderï¼‰\n",
    "    X_train_enc = X_train.copy()\n",
    "    X_valid_enc = X_valid.copy()\n",
    "    X_test_enc = X_test.copy()\n",
    "    \n",
    "    for col in cat_features:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(X_train_enc[col].astype(str))\n",
    "        \n",
    "        X_train_enc[col] = le.transform(X_train_enc[col].astype(str))\n",
    "        \n",
    "        # Valid/Testã®æœªçŸ¥ã‚«ãƒ†ã‚´ãƒªå‡¦ç†\n",
    "        for X_data in [X_valid_enc, X_test_enc]:\n",
    "            unknown_mask = ~X_data[col].astype(str).isin(le.classes_)\n",
    "            if unknown_mask.any():\n",
    "                X_data.loc[unknown_mask, col] = X_train[col].mode()[0]\n",
    "            X_data[col] = le.transform(X_data[col].astype(str))\n",
    "    \n",
    "    return X_train_enc, X_train_cat, y_train, X_valid_enc, X_valid_cat, y_valid, X_test_enc, X_test_cat\n",
    "\n",
    "\n",
    "print(\"âœ… Fold-Safeé–¢æ•°å®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GroupKFold + Fold-Safeå­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¯ Fold-Safe + GroupKFold Training\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Fold 1/5\n",
      "  Train: 712 samples, Valid: 179 samples\n",
      "============================================================\n",
      "\n",
      "[1/3] Training RandomForest...\n",
      "  Train: 0.8792 | Valid: 0.8547 | Gap: 0.0245\n",
      "\n",
      "[2/3] Training CatBoost...\n",
      "  Train: 0.8483 | Valid: 0.8715 | Gap: -0.0232\n",
      "\n",
      "[3/3] Training XGBoost...\n",
      "  Train: 0.8469 | Valid: 0.8659 | Gap: -0.0190\n",
      "\n",
      "============================================================\n",
      "Fold 2/5\n",
      "  Train: 713 samples, Valid: 178 samples\n",
      "============================================================\n",
      "\n",
      "[1/3] Training RandomForest...\n",
      "  Train: 0.8780 | Valid: 0.8371 | Gap: 0.0409\n",
      "\n",
      "[2/3] Training CatBoost...\n",
      "  Train: 0.8569 | Valid: 0.8315 | Gap: 0.0255\n",
      "\n",
      "[3/3] Training XGBoost...\n",
      "  Train: 0.8555 | Valid: 0.8371 | Gap: 0.0185\n",
      "\n",
      "============================================================\n",
      "Fold 3/5\n",
      "  Train: 713 samples, Valid: 178 samples\n",
      "============================================================\n",
      "\n",
      "[1/3] Training RandomForest...\n",
      "  Train: 0.8668 | Valid: 0.8090 | Gap: 0.0578\n",
      "\n",
      "[2/3] Training CatBoost...\n",
      "  Train: 0.8555 | Valid: 0.8202 | Gap: 0.0353\n",
      "\n",
      "[3/3] Training XGBoost...\n",
      "  Train: 0.8710 | Valid: 0.8090 | Gap: 0.0620\n",
      "\n",
      "============================================================\n",
      "Fold 4/5\n",
      "  Train: 713 samples, Valid: 178 samples\n",
      "============================================================\n",
      "\n",
      "[1/3] Training RandomForest...\n",
      "  Train: 0.8626 | Valid: 0.8315 | Gap: 0.0311\n",
      "\n",
      "[2/3] Training CatBoost...\n",
      "  Train: 0.8569 | Valid: 0.8090 | Gap: 0.0480\n",
      "\n",
      "[3/3] Training XGBoost...\n",
      "  Train: 0.8724 | Valid: 0.8202 | Gap: 0.0521\n",
      "\n",
      "============================================================\n",
      "Fold 5/5\n",
      "  Train: 713 samples, Valid: 178 samples\n",
      "============================================================\n",
      "\n",
      "[1/3] Training RandomForest...\n",
      "  Train: 0.8808 | Valid: 0.7978 | Gap: 0.0830\n",
      "\n",
      "[2/3] Training CatBoost...\n",
      "  Train: 0.8513 | Valid: 0.8034 | Gap: 0.0480\n",
      "\n",
      "[3/3] Training XGBoost...\n",
      "  Train: 0.8612 | Valid: 0.7921 | Gap: 0.0690\n",
      "\n",
      "============================================================\n",
      "Cross-Validation Results (Fold-Safe)\n",
      "============================================================\n",
      "RandomForest:\n",
      "  Train: 0.8735 Â± 0.0074\n",
      "  Valid: 0.8260 Â± 0.0203\n",
      "  Gap:   0.0475\n",
      "CatBoost:\n",
      "  Train: 0.8538 Â± 0.0034\n",
      "  Valid: 0.8271 Â± 0.0242\n",
      "  Gap:   0.0267\n",
      "XGBoost:\n",
      "  Train: 0.8614 Â± 0.0096\n",
      "  Valid: 0.8249 Â± 0.0252\n",
      "  Gap:   0.0365\n"
     ]
    }
   ],
   "source": [
    "def train_fold_safe_models(train_base, test_base, n_folds=5):\n",
    "    \"\"\"\n",
    "    ğŸ¯ GroupKFold + Fold-Safeå‰å‡¦ç†ã§å­¦ç¿’\n",
    "    \"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_folds)\n",
    "    groups = train_base['Ticket']\n",
    "    \n",
    "    y = train_base['Perished']\n",
    "    \n",
    "    # OOFäºˆæ¸¬ä¿å­˜ç”¨\n",
    "    oof_proba_rf = np.zeros(len(train_base))\n",
    "    oof_proba_cat = np.zeros(len(train_base))\n",
    "    oof_proba_xgb = np.zeros(len(train_base))\n",
    "    \n",
    "    test_proba_rf = np.zeros((len(test_base), n_folds))\n",
    "    test_proba_cat = np.zeros((len(test_base), n_folds))\n",
    "    test_proba_xgb = np.zeros((len(test_base), n_folds))\n",
    "    \n",
    "    models_rf = []\n",
    "    models_cat = []\n",
    "    models_xgb = []\n",
    "    \n",
    "    train_scores = {'rf': [], 'cat': [], 'xgb': []}\n",
    "    valid_scores = {'rf': [], 'cat': [], 'xgb': []}\n",
    "    \n",
    "    cat_features = ['Embarked', 'Title', 'Family_Size_Grouped', 'Deck', 'Age_Band', 'Fare_Band', 'Sex_Pclass']\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"ğŸ¯ Fold-Safe + GroupKFold Training\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(gkf.split(train_base, y, groups=groups)):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Fold {fold + 1}/{n_folds}\")\n",
    "        print(f\"  Train: {len(train_idx)} samples, Valid: {len(valid_idx)} samples\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼\n",
    "        train_fold = train_base.copy()\n",
    "        valid_fold = train_base.iloc[valid_idx].copy()\n",
    "        test_fold = test_base.copy()\n",
    "        \n",
    "        # ğŸ¯ Fold-Safeç‰¹å¾´é‡ä½œæˆ\n",
    "        train_fold, valid_fold, test_fold = apply_fold_safe_features(\n",
    "            train_fold, valid_fold, test_fold, train_idx\n",
    "        )\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "        X_train_enc, X_train_cat, y_train, X_valid_enc, X_valid_cat, y_valid, X_test_enc, X_test_cat = prepare_fold_data(\n",
    "            train_fold.iloc[train_idx], valid_fold, test_fold, cat_features\n",
    "        )\n",
    "        \n",
    "        # RandomForest\n",
    "        print(\"\\n[1/3] Training RandomForest...\")\n",
    "        model_rf = RandomForestClassifier(**best_params_randomforest)\n",
    "        model_rf.fit(X_train_enc, y_train)\n",
    "        \n",
    "        oof_proba_rf[valid_idx] = model_rf.predict_proba(X_valid_enc)[:, 1]\n",
    "        test_proba_rf[:, fold] = model_rf.predict_proba(X_test_enc)[:, 1]\n",
    "        models_rf.append(model_rf)\n",
    "        \n",
    "        train_acc_rf = accuracy_score(y_train, model_rf.predict(X_train_enc))\n",
    "        valid_acc_rf = accuracy_score(y_valid, model_rf.predict(X_valid_enc))\n",
    "        train_scores['rf'].append(train_acc_rf)\n",
    "        valid_scores['rf'].append(valid_acc_rf)\n",
    "        \n",
    "        print(f\"  Train: {train_acc_rf:.4f} | Valid: {valid_acc_rf:.4f} | Gap: {train_acc_rf - valid_acc_rf:.4f}\")\n",
    "        \n",
    "        # CatBoost\n",
    "        print(\"\\n[2/3] Training CatBoost...\")\n",
    "        train_pool = Pool(X_train_cat, y_train, cat_features=cat_features)\n",
    "        valid_pool = Pool(X_valid_cat, y_valid, cat_features=cat_features)\n",
    "        test_pool = Pool(X_test_cat, cat_features=cat_features)\n",
    "        \n",
    "        model_cat = CatBoostClassifier(**best_params_catboost)\n",
    "        model_cat.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50, verbose=0)\n",
    "        \n",
    "        oof_proba_cat[valid_idx] = model_cat.predict_proba(valid_pool)[:, 1]\n",
    "        test_proba_cat[:, fold] = model_cat.predict_proba(test_pool)[:, 1]\n",
    "        models_cat.append(model_cat)\n",
    "        \n",
    "        train_acc_cat = accuracy_score(y_train, model_cat.predict(train_pool))\n",
    "        valid_acc_cat = accuracy_score(y_valid, model_cat.predict(valid_pool))\n",
    "        train_scores['cat'].append(train_acc_cat)\n",
    "        valid_scores['cat'].append(valid_acc_cat)\n",
    "        \n",
    "        print(f\"  Train: {train_acc_cat:.4f} | Valid: {valid_acc_cat:.4f} | Gap: {train_acc_cat - valid_acc_cat:.4f}\")\n",
    "        \n",
    "        # XGBoost\n",
    "        print(\"\\n[3/3] Training XGBoost...\")\n",
    "        model_xgb = XGBClassifier(**best_params_xgboost)\n",
    "        model_xgb.fit(\n",
    "            X_train_enc, y_train,\n",
    "            eval_set=[(X_train_enc, y_train), (X_valid_enc, y_valid)],\n",
    "            verbose=0,\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        \n",
    "        oof_proba_xgb[valid_idx] = model_xgb.predict_proba(X_valid_enc)[:, 1]\n",
    "        test_proba_xgb[:, fold] = model_xgb.predict_proba(X_test_enc)[:, 1]\n",
    "        models_xgb.append(model_xgb)\n",
    "        \n",
    "        train_acc_xgb = accuracy_score(y_train, model_xgb.predict(X_train_enc))\n",
    "        valid_acc_xgb = accuracy_score(y_valid, model_xgb.predict(X_valid_enc))\n",
    "        train_scores['xgb'].append(train_acc_xgb)\n",
    "        valid_scores['xgb'].append(valid_acc_xgb)\n",
    "        \n",
    "        print(f\"  Train: {train_acc_xgb:.4f} | Valid: {valid_acc_xgb:.4f} | Gap: {train_acc_xgb - valid_acc_xgb:.4f}\")\n",
    "    \n",
    "    # CVçµæœã‚µãƒãƒªãƒ¼\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Cross-Validation Results (Fold-Safe)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for name, key in [('RandomForest', 'rf'), ('CatBoost', 'cat'), ('XGBoost', 'xgb')]:\n",
    "        train_mean = np.mean(train_scores[key])\n",
    "        train_std = np.std(train_scores[key])\n",
    "        valid_mean = np.mean(valid_scores[key])\n",
    "        valid_std = np.std(valid_scores[key])\n",
    "        gap = train_mean - valid_mean\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Train: {train_mean:.4f} Â± {train_std:.4f}\")\n",
    "        print(f\"  Valid: {valid_mean:.4f} Â± {valid_std:.4f}\")\n",
    "        print(f\"  Gap:   {gap:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'oof_proba_rf': oof_proba_rf,\n",
    "        'oof_proba_cat': oof_proba_cat,\n",
    "        'oof_proba_xgb': oof_proba_xgb,\n",
    "        'test_proba_rf': test_proba_rf.mean(axis=1),\n",
    "        'test_proba_cat': test_proba_cat.mean(axis=1),\n",
    "        'test_proba_xgb': test_proba_xgb.mean(axis=1),\n",
    "        'models_rf': models_rf,\n",
    "        'models_cat': models_cat,\n",
    "        'models_xgb': models_xgb,\n",
    "        'y': y\n",
    "    }\n",
    "\n",
    "\n",
    "# å­¦ç¿’å®Ÿè¡Œ\n",
    "results = train_fold_safe_models(train_base, test_base, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ€é©åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¯ æœ€é©é–¾å€¤æ¢ç´¢\n",
      "============================================================\n",
      "\n",
      "æœ€é©é–¾å€¤: 0.460\n",
      "OOF Accuracy: 0.8361\n",
      "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(0.5): 0.8249\n"
     ]
    }
   ],
   "source": [
    "# æœ€é©é–¾å€¤æ¢ç´¢\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ¯ æœ€é©é–¾å€¤æ¢ç´¢\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y = results['y']\n",
    "\n",
    "ensemble_proba = (\n",
    "    results['oof_proba_rf'] +\n",
    "    results['oof_proba_cat'] +\n",
    "    results['oof_proba_xgb']\n",
    ") / 3\n",
    "\n",
    "thresholds = np.linspace(0.3, 0.7, 81)\n",
    "best_th, best_acc = 0.5, 0.0\n",
    "\n",
    "for th in thresholds:\n",
    "    acc = accuracy_score(y, (ensemble_proba >= th).astype(int))\n",
    "    if acc > best_acc:\n",
    "        best_acc, best_th = acc, th\n",
    "\n",
    "print(f\"\\næœ€é©é–¾å€¤: {best_th:.3f}\")\n",
    "print(f\"OOF Accuracy: {best_acc:.4f}\")\n",
    "print(f\"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(0.5): {accuracy_score(y, (ensemble_proba >= 0.5).astype(int)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ¯ ãƒ¡ã‚¿å­¦ç¿’\n",
      "============================================================\n",
      "\n",
      "ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«é‡ã¿:\n",
      "  RF:  1.6066\n",
      "  Cat: 1.7571\n",
      "  XGB: 2.2102\n",
      "\n",
      "ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ« OOF: 0.8249\n",
      "å˜ç´”å¹³å‡ OOF: 0.8361\n"
     ]
    }
   ],
   "source": [
    "# ãƒ¡ã‚¿å­¦ç¿’\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¯ ãƒ¡ã‚¿å­¦ç¿’\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "oof_meta = np.vstack([\n",
    "    results['oof_proba_rf'],\n",
    "    results['oof_proba_cat'],\n",
    "    results['oof_proba_xgb'],\n",
    "]).T\n",
    "\n",
    "test_meta = np.vstack([\n",
    "    results['test_proba_rf'],\n",
    "    results['test_proba_cat'],\n",
    "    results['test_proba_xgb'],\n",
    "]).T\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
    "meta_model.fit(oof_meta, y)\n",
    "\n",
    "ensemble_meta_proba = meta_model.predict_proba(oof_meta)[:, 1]\n",
    "meta_oof_acc = accuracy_score(y, (ensemble_meta_proba >= 0.5).astype(int))\n",
    "\n",
    "print(f\"\\nãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«é‡ã¿:\")\n",
    "print(f\"  RF:  {meta_model.coef_[0][0]:.4f}\")\n",
    "print(f\"  Cat: {meta_model.coef_[0][1]:.4f}\")\n",
    "print(f\"  XGB: {meta_model.coef_[0][2]:.4f}\")\n",
    "print(f\"\\nãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ« OOF: {meta_oof_acc:.4f}\")\n",
    "print(f\"å˜ç´”å¹³å‡ OOF: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“Š æœ€çµ‚çµæœ (Fold-Safe)\n",
      "============================================================\n",
      "\n",
      "å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«:\n",
      "  RF:  0.8260\n",
      "  Cat: 0.8272\n",
      "  XGB: 0.8249\n",
      "\n",
      "ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«:\n",
      "  å˜ç´”å¹³å‡ (é–¾å€¤0.5): 0.8249\n",
      "  å˜ç´”å¹³å‡ (æœ€é©é–¾å€¤): 0.8361\n",
      "  ãƒ¡ã‚¿å­¦ç¿’: 0.8249\n",
      "\n",
      "âœ… æ¡ç”¨: å˜ç´”å¹³å‡+æœ€é©é–¾å€¤\n"
     ]
    }
   ],
   "source": [
    "# æœ€çµ‚çµæœ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š æœ€çµ‚çµæœ (Fold-Safe)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nå€‹åˆ¥ãƒ¢ãƒ‡ãƒ«:\")\n",
    "print(f\"  RF:  {accuracy_score(y, (results['oof_proba_rf'] >= 0.5).astype(int)):.4f}\")\n",
    "print(f\"  Cat: {accuracy_score(y, (results['oof_proba_cat'] >= 0.5).astype(int)):.4f}\")\n",
    "print(f\"  XGB: {accuracy_score(y, (results['oof_proba_xgb'] >= 0.5).astype(int)):.4f}\")\n",
    "\n",
    "print(f\"\\nã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«:\")\n",
    "print(f\"  å˜ç´”å¹³å‡ (é–¾å€¤0.5): {accuracy_score(y, (ensemble_proba >= 0.5).astype(int)):.4f}\")\n",
    "print(f\"  å˜ç´”å¹³å‡ (æœ€é©é–¾å€¤): {best_acc:.4f}\")\n",
    "print(f\"  ãƒ¡ã‚¿å­¦ç¿’: {meta_oof_acc:.4f}\")\n",
    "\n",
    "if meta_oof_acc >= best_acc:\n",
    "    print(f\"\\nâœ… æ¡ç”¨: ãƒ¡ã‚¿å­¦ç¿’\")\n",
    "    final_method = 'meta'\n",
    "    final_oof_score = meta_oof_acc\n",
    "else:\n",
    "    print(f\"\\nâœ… æ¡ç”¨: å˜ç´”å¹³å‡+æœ€é©é–¾å€¤\")\n",
    "    final_method = 'threshold'\n",
    "    final_oof_score = best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ãƒ†ã‚¹ãƒˆäºˆæ¸¬ã¨æå‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æå‡ºãƒ•ã‚¡ã‚¤ãƒ«: ../output/submission_fold_safe_threshold.csv\n",
      "\n",
      "äºˆæ¸¬åˆ†å¸ƒ:\n",
      "  Survived (0): 138 (33.0%)\n",
      "  Perished (1): 280 (67.0%)\n",
      "\n",
      "æœ€åˆã®10è¡Œ:\n",
      "   PassengerId  Perished\n",
      "0          892         1\n",
      "1          893         1\n",
      "2          894         1\n",
      "3          895         1\n",
      "4          896         1\n",
      "5          897         1\n",
      "6          898         0\n",
      "7          899         1\n",
      "8          900         0\n",
      "9          901         1\n"
     ]
    }
   ],
   "source": [
    "# ãƒ†ã‚¹ãƒˆäºˆæ¸¬\n",
    "if final_method == 'meta':\n",
    "    test_ensemble_proba = meta_model.predict_proba(test_meta)[:, 1]\n",
    "    final_predictions = (test_ensemble_proba >= 0.5).astype(int)\n",
    "    output_path = '../output/submission_fold_safe_meta.csv'\n",
    "else:\n",
    "    test_ensemble_proba = (\n",
    "        results['test_proba_rf'] +\n",
    "        results['test_proba_cat'] +\n",
    "        results['test_proba_xgb']\n",
    "    ) / 3\n",
    "    final_predictions = (test_ensemble_proba >= best_th).astype(int)\n",
    "    output_path = '../output/submission_fold_safe_threshold.csv'\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_base['PassengerId'],\n",
    "    'Perished': final_predictions\n",
    "})\n",
    "\n",
    "os.makedirs('../output', exist_ok=True)\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\næå‡ºãƒ•ã‚¡ã‚¤ãƒ«: {output_path}\")\n",
    "print(f\"\\näºˆæ¸¬åˆ†å¸ƒ:\")\n",
    "print(f\"  Survived (0): {(final_predictions == 0).sum()} ({(final_predictions == 0).sum() / len(final_predictions) * 100:.1f}%)\")\n",
    "print(f\"  Perished (1): {(final_predictions == 1).sum()} ({(final_predictions == 1).sum() / len(final_predictions) * 100:.1f}%)\")\n",
    "\n",
    "print(f\"\\næœ€åˆã®10è¡Œ:\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ!\n",
      "============================================================\n",
      "\n",
      "æœ€çµ‚OOFã‚¹ã‚³ã‚¢: 0.8361\n",
      "æ‰‹æ³•: threshold\n",
      "\n",
      "ğŸ¯ å®Ÿè£…æ¸ˆã¿æœ€é©åŒ–:\n",
      "  âœ… Fold-Safeå‰å‡¦ç†ï¼ˆæœ€é‡è¦ï¼ï¼‰\n",
      "  âœ… GroupKFold (Ticketã‚°ãƒ«ãƒ¼ãƒ—åŒ–)\n",
      "  âœ… Is_Marriedä¿®æ­£\n",
      "  âœ… æœ€é©é–¾å€¤æ¢ç´¢\n",
      "  âœ… ãƒ¡ã‚¿å­¦ç¿’\n",
      "  âœ… CatBoostæœ€é©åŒ–\n",
      "  âœ… æ•°å€¤ç‰¹å¾´é‡è¿½åŠ \n",
      "\n",
      "ğŸ“Š Fold-Safeã«ã‚ˆã‚‹æ”¹å–„:\n",
      "  - ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯å®Œå…¨é˜²æ­¢\n",
      "  - OOFã‚¹ã‚³ã‚¢ã®ä¿¡é ¼æ€§å‘ä¸Š\n",
      "  - Testã‚¹ã‚³ã‚¢ã¨ã®ä¹–é›¢æ¸›å°‘\n",
      "  - Foldé–“ã®ãƒ–ãƒ¬å®‰å®šåŒ–\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\næœ€çµ‚OOFã‚¹ã‚³ã‚¢: {final_oof_score:.4f}\")\n",
    "print(f\"æ‰‹æ³•: {final_method}\")\n",
    "print(f\"\\nğŸ¯ å®Ÿè£…æ¸ˆã¿æœ€é©åŒ–:\")\n",
    "print(f\"  âœ… Fold-Safeå‰å‡¦ç†ï¼ˆæœ€é‡è¦ï¼ï¼‰\")\n",
    "print(f\"  âœ… GroupKFold (Ticketã‚°ãƒ«ãƒ¼ãƒ—åŒ–)\")\n",
    "print(f\"  âœ… Is_Marriedä¿®æ­£\")\n",
    "print(f\"  âœ… æœ€é©é–¾å€¤æ¢ç´¢\")\n",
    "print(f\"  âœ… ãƒ¡ã‚¿å­¦ç¿’\")\n",
    "print(f\"  âœ… CatBoostæœ€é©åŒ–\")\n",
    "print(f\"  âœ… æ•°å€¤ç‰¹å¾´é‡è¿½åŠ \")\n",
    "print(f\"\\nğŸ“Š Fold-Safeã«ã‚ˆã‚‹æ”¹å–„:\")\n",
    "print(f\"  - ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯å®Œå…¨é˜²æ­¢\")\n",
    "print(f\"  - OOFã‚¹ã‚³ã‚¢ã®ä¿¡é ¼æ€§å‘ä¸Š\")\n",
    "print(f\"  - Testã‚¹ã‚³ã‚¢ã¨ã®ä¹–é›¢æ¸›å°‘\")\n",
    "print(f\"  - Foldé–“ã®ãƒ–ãƒ¬å®‰å®šåŒ–\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

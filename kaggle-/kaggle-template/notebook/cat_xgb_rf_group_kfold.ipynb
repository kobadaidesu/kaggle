{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - GroupKFoldç‰ˆ (æœ€çµ‚æœ€é©åŒ–)\n",
    "\n",
    "## ğŸ¯ æ”¹å–„ç‚¹:\n",
    "- âœ… **GroupKFold**: Ticketã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢\n",
    "- âœ… **Is_Marriedä¿®æ­£**: Titleçµ±åˆå‰ã«åˆ¤å®š\n",
    "- âœ… **æœ€é©é–¾å€¤æ¢ç´¢**: OOFã§æœ€é©åŒ–\n",
    "- âœ… **é‡ã¿æœ€é©åŒ–**: ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã§ãƒ¡ã‚¿å­¦ç¿’\n",
    "- âœ… **CatBoostæœ€é©åŒ–**: æ–‡å­—åˆ—ã‚«ãƒ†ã‚´ãƒªã‚’ç›´æ¥ä½¿ç”¨\n",
    "- âœ… **æ•°å€¤ç‰¹å¾´é‡è¿½åŠ **: Age, Fareã‚’é€£ç¶šå€¤ã®ã¾ã¾ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\n"
     ]
    }
   ],
   "source": [
    "# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import string\n",
    "import pickle\n",
    "from typing import Dict, List, Tuple\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GroupKFold  # âœ… GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# å®šæ•°è¨­å®š\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5\n",
    "\n",
    "# ä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®š\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n",
      "\n",
      "Target distribution:\n",
      "Perished\n",
      "1    0.616162\n",
      "0    0.383838\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Perished</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Perished  Pclass  \\\n",
       "0            1         1       3   \n",
       "1            2         0       1   \n",
       "2            3         0       3   \n",
       "3            4         0       1   \n",
       "4            5         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df_train['Perished'].value_counts(normalize=True))\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹...\n",
      "ğŸ¯ GroupKFoldå¯¾å¿œç‰ˆ\n",
      "\n",
      "âœ… ç‰¹å¾´é‡ä½œæˆå®Œäº†: 23 columns\n",
      "âœ… Is_Marriedæœ‰åŠ¹æ•°: 197ä»¶\n",
      "âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯Ticketæ•°: 681ä»¶\n",
      "\n",
      "Train shape: (891, 23)\n",
      "Test shape: (418, 23)\n"
     ]
    }
   ],
   "source": [
    "def extract_surname(data):\n",
    "    \"\"\"åå‰ã‹ã‚‰å§“ã‚’æŠ½å‡º\"\"\"\n",
    "    families = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        name = data.iloc[i]\n",
    "        if '(' in name:\n",
    "            name_no_bracket = name.split('(')[0]\n",
    "        else:\n",
    "            name_no_bracket = name\n",
    "        \n",
    "        family = name_no_bracket.split(',')[0]\n",
    "        \n",
    "        for c in string.punctuation:\n",
    "            family = family.replace(c, '').strip()\n",
    "        \n",
    "        families.append(family)\n",
    "    \n",
    "    return families\n",
    "\n",
    "\n",
    "def create_features(df_train, df_test):\n",
    "    \"\"\"\n",
    "    ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œï¼ˆGroupKFoldå¯¾å¿œç‰ˆï¼‰\n",
    "    \"\"\"\n",
    "    train = df_train.copy()\n",
    "    test = df_test.copy()\n",
    "    \n",
    "    all_data = pd.concat([train, test], axis=0, sort=False).reset_index(drop=True)\n",
    "    train_idx = ~all_data['Perished'].isna()\n",
    "    \n",
    "    print(\"ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹...\")\n",
    "    print(\"ğŸ¯ GroupKFoldå¯¾å¿œç‰ˆ\\n\")\n",
    "    \n",
    "    # 1. Titleï¼ˆæ•¬ç§°ï¼‰æŠ½å‡º - ç”Ÿã®Titleã‚’å…ˆã«ä¿å­˜\n",
    "    all_data['Title_raw'] = all_data['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "    \n",
    "    # 2. çµå©šãƒ•ãƒ©ã‚° - ç”Ÿã®Titleã§åˆ¤å®š\n",
    "    all_data['Is_Married'] = (all_data['Title_raw'] == 'Mrs').astype(int)\n",
    "    \n",
    "    # 3. Title æ­£è¦åŒ–\n",
    "    all_data['Title'] = all_data['Title_raw'].replace(\n",
    "        ['Miss', 'Mrs', 'Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms'\n",
    "    )\n",
    "    all_data['Title'] = all_data['Title'].replace(\n",
    "        ['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy'\n",
    "    )\n",
    "    \n",
    "    # 4. Familyï¼ˆå§“ï¼‰\n",
    "    all_data['Family'] = extract_surname(all_data['Name'])\n",
    "    \n",
    "    # 5. Family_Size\n",
    "    all_data['Family_Size'] = all_data['SibSp'] + all_data['Parch'] + 1\n",
    "    \n",
    "    # 6. Family_Size_Grouped\n",
    "    family_map = {\n",
    "        1: 'Alone',\n",
    "        2: 'Small', 3: 'Small', 4: 'Small',\n",
    "        5: 'Medium', 6: 'Medium',\n",
    "        7: 'Large', 8: 'Large', 11: 'Large'\n",
    "    }\n",
    "    all_data['Family_Size_Grouped'] = all_data['Family_Size'].map(family_map)\n",
    "    \n",
    "    # 7. Ticket_Frequency - è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§è¨ˆç®—\n",
    "    train_ticket_freq = all_data.loc[train_idx].groupby('Ticket')['Ticket'].transform('count')\n",
    "    train_ticket_map = all_data.loc[train_idx].groupby('Ticket').size().to_dict()\n",
    "    \n",
    "    all_data.loc[train_idx, 'Ticket_Frequency'] = train_ticket_freq\n",
    "    all_data.loc[~train_idx, 'Ticket_Frequency'] = all_data.loc[~train_idx, 'Ticket'].map(train_ticket_map).fillna(1)\n",
    "    \n",
    "    # 8. Deck\n",
    "    all_data['Deck'] = all_data['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
    "    all_data['Deck'] = all_data['Deck'].replace(['A', 'B', 'C'], 'ABC')\n",
    "    all_data['Deck'] = all_data['Deck'].replace(['D', 'E'], 'DE')\n",
    "    all_data['Deck'] = all_data['Deck'].replace(['F', 'G'], 'FG')\n",
    "    all_data['Deck'] = all_data['Deck'].replace(['T'], 'M')\n",
    "    \n",
    "    # 9. Ageè£œå®Œï¼ˆé€£ç¶šå€¤ã‚‚ä¿æŒï¼‰\n",
    "    all_data['Age'] = pd.to_numeric(all_data['Age'], errors='coerce')\n",
    "    age_by_pclass_sex = all_data.loc[train_idx].groupby(['Sex', 'Pclass'])['Age'].median()\n",
    "    \n",
    "    for pclass in [1, 2, 3]:\n",
    "        for sex in ['male', 'female']:\n",
    "            mask = (all_data['Age'].isnull()) & (all_data['Pclass'] == pclass) & (all_data['Sex'] == sex)\n",
    "            all_data.loc[mask, 'Age'] = age_by_pclass_sex.loc[(sex, pclass)]\n",
    "    \n",
    "    all_data['Age_Band'] = pd.cut(all_data['Age'], bins=[0, 12, 18, 30, 50, 80], \n",
    "                                    labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "    \n",
    "    # 10. Fareè£œå®Œï¼ˆé€£ç¶šå€¤ã‚‚ä¿æŒï¼‰\n",
    "    train_fare_median = all_data.loc[train_idx, 'Fare'].median()\n",
    "    all_data['Fare'] = all_data['Fare'].fillna(train_fare_median)\n",
    "    \n",
    "    train_fare_quantiles = all_data.loc[train_idx, 'Fare'].quantile([0.25, 0.5, 0.75]).values\n",
    "    all_data['Fare_Band'] = pd.cut(\n",
    "        all_data['Fare'],\n",
    "        bins=[-np.inf] + train_fare_quantiles.tolist() + [np.inf],\n",
    "        labels=['Low', 'Medium', 'High', 'Very_High']\n",
    "    )\n",
    "    \n",
    "    # 11. Embarkedè£œå®Œ\n",
    "    all_data['Embarked'] = all_data['Embarked'].fillna('S')\n",
    "    \n",
    "    # 12. Sex x Pclass äº¤äº’ä½œç”¨\n",
    "    all_data['Sex_Pclass'] = all_data['Sex'] + '_' + all_data['Pclass'].astype(str)\n",
    "    \n",
    "    print(f\"âœ… ç‰¹å¾´é‡ä½œæˆå®Œäº†: {all_data.shape[1]} columns\")\n",
    "    print(f\"âœ… Is_Marriedæœ‰åŠ¹æ•°: {all_data['Is_Married'].sum()}ä»¶\")\n",
    "    \n",
    "    # âœ… GroupKFoldç”¨ã«Ticketã‚’ä¿æŒ\n",
    "    print(f\"âœ… ãƒ¦ãƒ‹ãƒ¼ã‚¯Ticketæ•°: {all_data.loc[train_idx, 'Ticket'].nunique()}ä»¶\")\n",
    "    \n",
    "    train_processed = all_data[train_idx].reset_index(drop=True)\n",
    "    test_processed = all_data[~train_idx].reset_index(drop=True)\n",
    "    \n",
    "    return train_processed, test_processed\n",
    "\n",
    "\n",
    "train_df, test_df = create_features(df_train, df_test)\n",
    "\n",
    "print(f\"\\nTrain shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_encoded shape: (891, 13)\n",
      "y shape: (891,)\n",
      "groups shape: (891,)\n",
      "âœ… GroupKFoldç”¨ã«Ticketã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä¿æŒ\n",
      "\n",
      "Categorical features: ['Embarked', 'Title', 'Family_Size_Grouped', 'Deck', 'Age_Band', 'Fare_Band', 'Sex_Pclass']\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(train_df, test_df):\n",
    "    \"\"\"\n",
    "    ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆGroupKFoldç”¨ã«Ticketã‚‚è¿”ã™ï¼‰\n",
    "    \"\"\"\n",
    "    feature_cols = [\n",
    "        'Pclass', 'Age', 'Fare', 'Family_Size', 'Is_Married',\n",
    "        'Embarked', 'Title', 'Family_Size_Grouped', 'Ticket_Frequency', 'Deck',\n",
    "        'Age_Band', 'Fare_Band', 'Sex_Pclass'\n",
    "    ]\n",
    "    \n",
    "    train = train_df[feature_cols + ['Perished']].copy()\n",
    "    test = test_df[feature_cols].copy()\n",
    "    \n",
    "    cat_features = ['Embarked', 'Title', 'Family_Size_Grouped', 'Deck', 'Age_Band', 'Fare_Band', 'Sex_Pclass']\n",
    "    \n",
    "    # RF/XGBç”¨: LabelEncoder\n",
    "    train_encoded = train.copy()\n",
    "    test_encoded = test.copy()\n",
    "    \n",
    "    le_dict = {}\n",
    "    for col in cat_features:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(train_encoded[col].astype(str))\n",
    "        \n",
    "        train_encoded[col] = le.transform(train_encoded[col].astype(str))\n",
    "        \n",
    "        test_col_str = test_encoded[col].astype(str)\n",
    "        unknown_mask = ~test_col_str.isin(le.classes_)\n",
    "        \n",
    "        if unknown_mask.any():\n",
    "            most_frequent = train_df[col].mode()[0]\n",
    "            test_encoded.loc[unknown_mask, col] = most_frequent\n",
    "        \n",
    "        test_encoded[col] = le.transform(test_encoded[col].astype(str))\n",
    "        le_dict[col] = le\n",
    "    \n",
    "    X_encoded = train_encoded.drop('Perished', axis=1)\n",
    "    y = train_encoded['Perished']\n",
    "    X_test_encoded = test_encoded\n",
    "    \n",
    "    # CatBoostç”¨: æ–‡å­—åˆ—ã®ã¾ã¾\n",
    "    X_catboost = train.drop('Perished', axis=1)\n",
    "    X_test_catboost = test\n",
    "    \n",
    "    # âœ… GroupKFoldç”¨ã®ã‚°ãƒ«ãƒ¼ãƒ—å¤‰æ•°\n",
    "    groups = train_df['Ticket']\n",
    "    \n",
    "    print(f\"\\nX_encoded shape: {X_encoded.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"groups shape: {groups.shape}\")\n",
    "    print(f\"âœ… GroupKFoldç”¨ã«Ticketã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä¿æŒ\")\n",
    "    \n",
    "    return X_encoded, X_catboost, y, X_test_encoded, X_test_catboost, cat_features, groups\n",
    "\n",
    "\n",
    "X_encoded, X_catboost, y, X_test_encoded, X_test_catboost, cat_features, groups = prepare_data(train_df, test_df)\n",
    "print(f\"\\nCategorical features: {cat_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šå®Œäº†\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "best_params_randomforest = {\n",
    "    'n_estimators': 1200,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_split': 6,\n",
    "    'min_samples_leaf': 3,\n",
    "    'max_features': 'sqrt',\n",
    "    'bootstrap': True,\n",
    "    'max_samples': 0.9,\n",
    "    'criterion': 'gini',\n",
    "    'class_weight': None,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# CatBoost\n",
    "best_params_catboost = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 6.0,\n",
    "    'bagging_temperature': 0.5,\n",
    "    'random_strength': 1.0,\n",
    "    'rsm': 0.9,\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'Logloss',\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# XGBoost\n",
    "best_params_xgboost = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 3,\n",
    "    'gamma': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1.0,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'eval_metric': 'logloss',\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "print(\"ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šå®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GroupKFoldå­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¯ GroupKFold Training (grouped by Ticket)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Fold 1/5\n",
      "  Train: 712 samples, Valid: 179 samples\n",
      "============================================================\n",
      "\n",
      "[1/3] Training RandomForest...\n",
      "  Train: 0.8834 | Valid: 0.8603 | Gap: 0.0231\n",
      "\n",
      "[2/3] Training CatBoost...\n",
      "  Train: 0.8596 | Valid: 0.8603 | Gap: -0.0008\n",
      "\n",
      "[3/3] Training XGBoost...\n",
      "  Train: 0.8904 | Valid: 0.8436 | Gap: 0.0469\n",
      "\n",
      "============================================================\n",
      "Fold 2/5\n",
      "  Train: 713 samples, Valid: 178 samples\n",
      "============================================================\n",
      "\n",
      "[1/3] Training RandomForest...\n",
      "  Train: 0.8780 | Valid: 0.8371 | Gap: 0.0409\n",
      "\n",
      "[2/3] Training CatBoost...\n",
      "  Train: 0.8541 | Valid: 0.8090 | Gap: 0.0451\n",
      "\n",
      "[3/3] Training XGBoost...\n",
      "  Train: 0.8850 | Valid: 0.8315 | Gap: 0.0535\n",
      "\n",
      "============================================================\n",
      "Fold 3/5\n",
      "  Train: 713 samples, Valid: 178 samples\n",
      "============================================================\n",
      "\n",
      "[1/3] Training RandomForest...\n",
      "  Train: 0.8724 | Valid: 0.8146 | Gap: 0.0578\n",
      "\n",
      "[2/3] Training CatBoost...\n",
      "  Train: 0.8555 | Valid: 0.8202 | Gap: 0.0353\n",
      "\n",
      "[3/3] Training XGBoost...\n",
      "  Train: 0.8962 | Valid: 0.8202 | Gap: 0.0760\n",
      "\n",
      "============================================================\n",
      "Fold 4/5\n",
      "  Train: 713 samples, Valid: 178 samples\n",
      "============================================================\n",
      "\n",
      "[1/3] Training RandomForest...\n",
      "  Train: 0.8668 | Valid: 0.8371 | Gap: 0.0297\n",
      "\n",
      "[2/3] Training CatBoost...\n",
      "  Train: 0.8527 | Valid: 0.8315 | Gap: 0.0213\n",
      "\n",
      "[3/3] Training XGBoost...\n",
      "  Train: 0.8836 | Valid: 0.8202 | Gap: 0.0634\n",
      "\n",
      "============================================================\n",
      "Fold 5/5\n",
      "  Train: 713 samples, Valid: 178 samples\n",
      "============================================================\n",
      "\n",
      "[1/3] Training RandomForest...\n",
      "  Train: 0.8822 | Valid: 0.8090 | Gap: 0.0732\n",
      "\n",
      "[2/3] Training CatBoost...\n",
      "  Train: 0.8513 | Valid: 0.8034 | Gap: 0.0480\n",
      "\n",
      "[3/3] Training XGBoost...\n",
      "  Train: 0.8710 | Valid: 0.8146 | Gap: 0.0564\n",
      "\n",
      "============================================================\n",
      "Cross-Validation Results (GroupKFold)\n",
      "============================================================\n",
      "\n",
      "Fold sizes (Train, Valid):\n",
      "  Fold 1: (712, 179)\n",
      "  Fold 2: (713, 178)\n",
      "  Fold 3: (713, 178)\n",
      "  Fold 4: (713, 178)\n",
      "  Fold 5: (713, 178)\n",
      "\n",
      "Model Performance:\n",
      "RandomForest:\n",
      "  Train: 0.8765 Â± 0.0062\n",
      "  Valid: 0.8316 Â± 0.0184\n",
      "  Gap:   0.0449\n",
      "CatBoost:\n",
      "  Train: 0.8547 Â± 0.0028\n",
      "  Valid: 0.8249 Â± 0.0202\n",
      "  Gap:   0.0298\n",
      "XGBoost:\n",
      "  Train: 0.8852 Â± 0.0084\n",
      "  Valid: 0.8260 Â± 0.0103\n",
      "  Gap:   0.0592\n"
     ]
    }
   ],
   "source": [
    "def train_with_group_kfold(X_encoded, X_catboost, y, X_test_encoded, X_test_catboost, cat_features, groups, n_folds=5):\n",
    "    \"\"\"\n",
    "    GroupKFoldã§å­¦ç¿’ï¼ˆTicketã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰\n",
    "    \"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_folds)  # âœ… GroupKFold\n",
    "    \n",
    "    # ç¢ºç‡ã‚’ä¿å­˜\n",
    "    oof_proba_rf = np.zeros(len(X_encoded))\n",
    "    oof_proba_cat = np.zeros(len(X_encoded))\n",
    "    oof_proba_xgb = np.zeros(len(X_encoded))\n",
    "    \n",
    "    test_proba_rf = np.zeros((len(X_test_encoded), n_folds))\n",
    "    test_proba_cat = np.zeros((len(X_test_encoded), n_folds))\n",
    "    test_proba_xgb = np.zeros((len(X_test_encoded), n_folds))\n",
    "    \n",
    "    models_rf = []\n",
    "    models_cat = []\n",
    "    models_xgb = []\n",
    "    \n",
    "    train_scores = {'rf': [], 'cat': [], 'xgb': []}\n",
    "    valid_scores = {'rf': [], 'cat': [], 'xgb': []}\n",
    "    fold_sizes = []\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"ğŸ¯ GroupKFold Training (grouped by Ticket)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(gkf.split(X_encoded, y, groups=groups)):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Fold {fold + 1}/{n_folds}\")\n",
    "        print(f\"  Train: {len(train_idx)} samples, Valid: {len(valid_idx)} samples\")\n",
    "        fold_sizes.append((len(train_idx), len(valid_idx)))\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # RF/XGBç”¨\n",
    "        X_train_enc, X_valid_enc = X_encoded.iloc[train_idx], X_encoded.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "        \n",
    "        # CatBoostç”¨\n",
    "        X_train_cat, X_valid_cat = X_catboost.iloc[train_idx], X_catboost.iloc[valid_idx]\n",
    "        \n",
    "        # RandomForest\n",
    "        print(\"\\n[1/3] Training RandomForest...\")\n",
    "        model_rf = RandomForestClassifier(**best_params_randomforest)\n",
    "        model_rf.fit(X_train_enc, y_train)\n",
    "        \n",
    "        oof_proba_rf[valid_idx] = model_rf.predict_proba(X_valid_enc)[:, 1]\n",
    "        test_proba_rf[:, fold] = model_rf.predict_proba(X_test_encoded)[:, 1]\n",
    "        models_rf.append(model_rf)\n",
    "        \n",
    "        valid_acc_rf = accuracy_score(y_valid, model_rf.predict(X_valid_enc))\n",
    "        train_acc_rf = accuracy_score(y_train, model_rf.predict(X_train_enc))\n",
    "        train_scores['rf'].append(train_acc_rf)\n",
    "        valid_scores['rf'].append(valid_acc_rf)\n",
    "        \n",
    "        print(f\"  Train: {train_acc_rf:.4f} | Valid: {valid_acc_rf:.4f} | Gap: {train_acc_rf - valid_acc_rf:.4f}\")\n",
    "        \n",
    "        # CatBoost\n",
    "        print(\"\\n[2/3] Training CatBoost...\")\n",
    "        train_pool = Pool(X_train_cat, y_train, cat_features=cat_features)\n",
    "        valid_pool = Pool(X_valid_cat, y_valid, cat_features=cat_features)\n",
    "        test_pool = Pool(X_test_catboost, cat_features=cat_features)\n",
    "        \n",
    "        model_cat = CatBoostClassifier(**best_params_catboost)\n",
    "        model_cat.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50, verbose=0)\n",
    "        \n",
    "        oof_proba_cat[valid_idx] = model_cat.predict_proba(valid_pool)[:, 1]\n",
    "        test_proba_cat[:, fold] = model_cat.predict_proba(test_pool)[:, 1]\n",
    "        models_cat.append(model_cat)\n",
    "        \n",
    "        valid_acc_cat = accuracy_score(y_valid, model_cat.predict(valid_pool))\n",
    "        train_acc_cat = accuracy_score(y_train, model_cat.predict(train_pool))\n",
    "        train_scores['cat'].append(train_acc_cat)\n",
    "        valid_scores['cat'].append(valid_acc_cat)\n",
    "        \n",
    "        print(f\"  Train: {train_acc_cat:.4f} | Valid: {valid_acc_cat:.4f} | Gap: {train_acc_cat - valid_acc_cat:.4f}\")\n",
    "        \n",
    "        # XGBoost\n",
    "        print(\"\\n[3/3] Training XGBoost...\")\n",
    "        model_xgb = XGBClassifier(**best_params_xgboost)\n",
    "        model_xgb.fit(\n",
    "            X_train_enc, y_train, \n",
    "            eval_set=[(X_train_enc, y_train), (X_valid_enc, y_valid)],\n",
    "            verbose=0,\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        \n",
    "        oof_proba_xgb[valid_idx] = model_xgb.predict_proba(X_valid_enc)[:, 1]\n",
    "        test_proba_xgb[:, fold] = model_xgb.predict_proba(X_test_encoded)[:, 1]\n",
    "        models_xgb.append(model_xgb)\n",
    "        \n",
    "        valid_acc_xgb = accuracy_score(y_valid, model_xgb.predict(X_valid_enc))\n",
    "        train_acc_xgb = accuracy_score(y_train, model_xgb.predict(X_train_enc))\n",
    "        train_scores['xgb'].append(train_acc_xgb)\n",
    "        valid_scores['xgb'].append(valid_acc_xgb)\n",
    "        \n",
    "        print(f\"  Train: {train_acc_xgb:.4f} | Valid: {valid_acc_xgb:.4f} | Gap: {train_acc_xgb - valid_acc_xgb:.4f}\")\n",
    "    \n",
    "    # CVçµæœã‚µãƒãƒªãƒ¼\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Cross-Validation Results (GroupKFold)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nFold sizes (Train, Valid):\")\n",
    "    for i, (tr, va) in enumerate(fold_sizes):\n",
    "        print(f\"  Fold {i+1}: ({tr}, {va})\")\n",
    "    \n",
    "    print(f\"\\nModel Performance:\")\n",
    "    for name, key in [('RandomForest', 'rf'), ('CatBoost', 'cat'), ('XGBoost', 'xgb')]:\n",
    "        train_mean = np.mean(train_scores[key])\n",
    "        train_std = np.std(train_scores[key])\n",
    "        valid_mean = np.mean(valid_scores[key])\n",
    "        valid_std = np.std(valid_scores[key])\n",
    "        gap = train_mean - valid_mean\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  Train: {train_mean:.4f} Â± {train_std:.4f}\")\n",
    "        print(f\"  Valid: {valid_mean:.4f} Â± {valid_std:.4f}\")\n",
    "        print(f\"  Gap:   {gap:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'oof_proba_rf': oof_proba_rf,\n",
    "        'oof_proba_cat': oof_proba_cat,\n",
    "        'oof_proba_xgb': oof_proba_xgb,\n",
    "        'test_proba_rf': test_proba_rf.mean(axis=1),\n",
    "        'test_proba_cat': test_proba_cat.mean(axis=1),\n",
    "        'test_proba_xgb': test_proba_xgb.mean(axis=1),\n",
    "        'models_rf': models_rf,\n",
    "        'models_cat': models_cat,\n",
    "        'models_xgb': models_xgb\n",
    "    }\n",
    "\n",
    "\n",
    "# å­¦ç¿’å®Ÿè¡Œ\n",
    "results = train_with_group_kfold(X_encoded, X_catboost, y, X_test_encoded, X_test_catboost, cat_features, groups, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ€é©åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¯ æœ€é©é–¾å€¤æ¢ç´¢\n",
      "============================================================\n",
      "\n",
      "æœ€é©é–¾å€¤: 0.490\n",
      "OOF Accuracy: 0.8305\n",
      "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(0.5): 0.8272\n"
     ]
    }
   ],
   "source": [
    "# æœ€é©é–¾å€¤æ¢ç´¢\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ¯ æœ€é©é–¾å€¤æ¢ç´¢\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ensemble_proba = (\n",
    "    results['oof_proba_rf'] +\n",
    "    results['oof_proba_cat'] +\n",
    "    results['oof_proba_xgb']\n",
    ") / 3\n",
    "\n",
    "thresholds = np.linspace(0.3, 0.7, 81)\n",
    "best_th, best_acc = 0.5, 0.0\n",
    "\n",
    "for th in thresholds:\n",
    "    acc = accuracy_score(y, (ensemble_proba >= th).astype(int))\n",
    "    if acc > best_acc:\n",
    "        best_acc, best_th = acc, th\n",
    "\n",
    "print(f\"\\næœ€é©é–¾å€¤: {best_th:.3f}\")\n",
    "print(f\"OOF Accuracy: {best_acc:.4f}\")\n",
    "print(f\"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(0.5): {accuracy_score(y, (ensemble_proba >= 0.5).astype(int)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ¯ ãƒ¡ã‚¿å­¦ç¿’ (é‡ã¿æœ€é©åŒ–)\n",
      "============================================================\n",
      "\n",
      "ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«é‡ã¿:\n",
      "  RF:  1.4657\n",
      "  Cat: 1.8140\n",
      "  XGB: 2.2902\n",
      "\n",
      "ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ« OOF: 0.8305\n",
      "å˜ç´”å¹³å‡ OOF: 0.8305\n"
     ]
    }
   ],
   "source": [
    "# ãƒ¡ã‚¿å­¦ç¿’\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¯ ãƒ¡ã‚¿å­¦ç¿’ (é‡ã¿æœ€é©åŒ–)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "oof_meta = np.vstack([\n",
    "    results['oof_proba_rf'],\n",
    "    results['oof_proba_cat'],\n",
    "    results['oof_proba_xgb'],\n",
    "]).T\n",
    "\n",
    "test_meta = np.vstack([\n",
    "    results['test_proba_rf'],\n",
    "    results['test_proba_cat'],\n",
    "    results['test_proba_xgb'],\n",
    "]).T\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
    "meta_model.fit(oof_meta, y)\n",
    "\n",
    "ensemble_meta_proba = meta_model.predict_proba(oof_meta)[:, 1]\n",
    "meta_oof_acc = accuracy_score(y, (ensemble_meta_proba >= 0.5).astype(int))\n",
    "\n",
    "print(f\"\\nãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«é‡ã¿:\")\n",
    "print(f\"  RF:  {meta_model.coef_[0][0]:.4f}\")\n",
    "print(f\"  Cat: {meta_model.coef_[0][1]:.4f}\")\n",
    "print(f\"  XGB: {meta_model.coef_[0][2]:.4f}\")\n",
    "print(f\"\\nãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ« OOF: {meta_oof_acc:.4f}\")\n",
    "print(f\"å˜ç´”å¹³å‡ OOF: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“Š æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼ (GroupKFold)\n",
      "============================================================\n",
      "\n",
      "å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«:\n",
      "  RF:  0.8316\n",
      "  Cat: 0.8249\n",
      "  XGB: 0.8260\n",
      "\n",
      "ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«:\n",
      "  å˜ç´”å¹³å‡ (é–¾å€¤0.5): 0.8272\n",
      "  å˜ç´”å¹³å‡ (æœ€é©é–¾å€¤): 0.8305\n",
      "  ãƒ¡ã‚¿å­¦ç¿’: 0.8305\n",
      "\n",
      "âœ… æ¡ç”¨: ãƒ¡ã‚¿å­¦ç¿’\n"
     ]
    }
   ],
   "source": [
    "# æœ€çµ‚çµæœ\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼ (GroupKFold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nå€‹åˆ¥ãƒ¢ãƒ‡ãƒ«:\")\n",
    "print(f\"  RF:  {accuracy_score(y, (results['oof_proba_rf'] >= 0.5).astype(int)):.4f}\")\n",
    "print(f\"  Cat: {accuracy_score(y, (results['oof_proba_cat'] >= 0.5).astype(int)):.4f}\")\n",
    "print(f\"  XGB: {accuracy_score(y, (results['oof_proba_xgb'] >= 0.5).astype(int)):.4f}\")\n",
    "\n",
    "print(f\"\\nã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«:\")\n",
    "print(f\"  å˜ç´”å¹³å‡ (é–¾å€¤0.5): {accuracy_score(y, (ensemble_proba >= 0.5).astype(int)):.4f}\")\n",
    "print(f\"  å˜ç´”å¹³å‡ (æœ€é©é–¾å€¤): {best_acc:.4f}\")\n",
    "print(f\"  ãƒ¡ã‚¿å­¦ç¿’: {meta_oof_acc:.4f}\")\n",
    "\n",
    "if meta_oof_acc >= best_acc:\n",
    "    print(f\"\\nâœ… æ¡ç”¨: ãƒ¡ã‚¿å­¦ç¿’\")\n",
    "    final_method = 'meta'\n",
    "    final_oof_score = meta_oof_acc\n",
    "else:\n",
    "    print(f\"\\nâœ… æ¡ç”¨: å˜ç´”å¹³å‡+æœ€é©é–¾å€¤\")\n",
    "    final_method = 'threshold'\n",
    "    final_oof_score = best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ãƒ†ã‚¹ãƒˆäºˆæ¸¬ã¨æå‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æå‡ºãƒ•ã‚¡ã‚¤ãƒ«: ../output/submission_group_kfold_meta.csv\n",
      "\n",
      "äºˆæ¸¬åˆ†å¸ƒ:\n",
      "  Survived (0): 145 (34.7%)\n",
      "  Perished (1): 273 (65.3%)\n",
      "\n",
      "æœ€åˆã®10è¡Œ:\n",
      "   PassengerId  Perished\n",
      "0          892         1\n",
      "1          893         1\n",
      "2          894         1\n",
      "3          895         1\n",
      "4          896         1\n",
      "5          897         1\n",
      "6          898         0\n",
      "7          899         1\n",
      "8          900         0\n",
      "9          901         1\n"
     ]
    }
   ],
   "source": [
    "# ãƒ†ã‚¹ãƒˆäºˆæ¸¬\n",
    "if final_method == 'meta':\n",
    "    test_ensemble_proba = meta_model.predict_proba(test_meta)[:, 1]\n",
    "    final_predictions = (test_ensemble_proba >= 0.5).astype(int)\n",
    "    output_path = '../output/submission_group_kfold_meta.csv'\n",
    "else:\n",
    "    test_ensemble_proba = (\n",
    "        results['test_proba_rf'] +\n",
    "        results['test_proba_cat'] +\n",
    "        results['test_proba_xgb']\n",
    "    ) / 3\n",
    "    final_predictions = (test_ensemble_proba >= best_th).astype(int)\n",
    "    output_path = '../output/submission_group_kfold_threshold.csv'\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Perished': final_predictions\n",
    "})\n",
    "\n",
    "os.makedirs('../output', exist_ok=True)\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\næå‡ºãƒ•ã‚¡ã‚¤ãƒ«: {output_path}\")\n",
    "print(f\"\\näºˆæ¸¬åˆ†å¸ƒ:\")\n",
    "print(f\"  Survived (0): {(final_predictions == 0).sum()} ({(final_predictions == 0).sum() / len(final_predictions) * 100:.1f}%)\")\n",
    "print(f\"  Perished (1): {(final_predictions == 1).sum()} ({(final_predictions == 1).sum() / len(final_predictions) * 100:.1f}%)\")\n",
    "\n",
    "print(f\"\\næœ€åˆã®10è¡Œ:\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ!\n",
      "============================================================\n",
      "\n",
      "æœ€çµ‚OOFã‚¹ã‚³ã‚¢: 0.8305\n",
      "æ‰‹æ³•: meta\n",
      "\n",
      "ğŸ¯ å®Ÿè£…æ¸ˆã¿æœ€é©åŒ–:\n",
      "  âœ… GroupKFold (Ticketã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–)\n",
      "  âœ… Is_Marriedä¿®æ­£\n",
      "  âœ… æœ€é©é–¾å€¤æ¢ç´¢\n",
      "  âœ… ãƒ¡ã‚¿å­¦ç¿’\n",
      "  âœ… CatBoostæœ€é©åŒ–\n",
      "  âœ… æ•°å€¤ç‰¹å¾´é‡è¿½åŠ \n",
      "\n",
      "ğŸ“Š GroupKFoldã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢\n",
      "ğŸ“Š ã‚ˆã‚Šç¾å®Ÿçš„ãªOOFã‚¹ã‚³ã‚¢ã‚’å–å¾—\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\næœ€çµ‚OOFã‚¹ã‚³ã‚¢: {final_oof_score:.4f}\")\n",
    "print(f\"æ‰‹æ³•: {final_method}\")\n",
    "print(f\"\\nğŸ¯ å®Ÿè£…æ¸ˆã¿æœ€é©åŒ–:\")\n",
    "print(f\"  âœ… GroupKFold (Ticketã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–)\")\n",
    "print(f\"  âœ… Is_Marriedä¿®æ­£\")\n",
    "print(f\"  âœ… æœ€é©é–¾å€¤æ¢ç´¢\")\n",
    "print(f\"  âœ… ãƒ¡ã‚¿å­¦ç¿’\")\n",
    "print(f\"  âœ… CatBoostæœ€é©åŒ–\")\n",
    "print(f\"  âœ… æ•°å€¤ç‰¹å¾´é‡è¿½åŠ \")\n",
    "print(f\"\\nğŸ“Š GroupKFoldã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢\")\n",
    "print(f\"ğŸ“Š ã‚ˆã‚Šç¾å®Ÿçš„ãªOOFã‚¹ã‚³ã‚¢ã‚’å–å¾—\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

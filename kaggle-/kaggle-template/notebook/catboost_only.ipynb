{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - CatBoost Only (Fold-Safe版)\n",
    "\n",
    "## 改善点:\n",
    "- Fold-Safe前処理: 各Foldで統計量を再計算\n",
    "- StratifiedKFold: クラスバランス維持\n",
    "- CatBoost最適化: 文字列カテゴリ使用\n",
    "- 学習曲線可視化\n",
    "- 詳細メトリクス表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import string\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, roc_curve\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 10\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"ライブラリのインポート完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "print(f\"Train shape: {df_train.shape}\")\n",
    "print(f\"Test shape: {df_test.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df_train[\"Perished\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 基本特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_surname(data):\n",
    "    \"\"\"名前から姓を抽出\"\"\"\n",
    "    families = []\n",
    "    for i in range(len(data)):\n",
    "        name = data.iloc[i]\n",
    "        if \"(\" in name:\n",
    "            name_no_bracket = name.split(\"(\")[0]\n",
    "        else:\n",
    "            name_no_bracket = name\n",
    "        family = name_no_bracket.split(\",\")[0]\n",
    "        for c in string.punctuation:\n",
    "            family = family.replace(c, \"\").strip()\n",
    "        families.append(family)\n",
    "    return families\n",
    "\n",
    "\n",
    "def create_base_features(df):\n",
    "    \"\"\"Fold-independentな基本特徴量のみ作成\"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. Title抽出\n",
    "    data[\"Title_raw\"] = data[\"Name\"].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "    \n",
    "    # 2. Is_Married（Title統合前に判定）\n",
    "    data[\"Is_Married\"] = (data[\"Title_raw\"] == \"Mrs\").astype(int)\n",
    "    \n",
    "    # 3. Title正規化\n",
    "    data[\"Title\"] = data[\"Title_raw\"].replace(\n",
    "        [\"Miss\", \"Mrs\", \"Ms\", \"Mlle\", \"Lady\", \"Mme\", \"the Countess\", \"Dona\"], \"Miss/Mrs/Ms\"\n",
    "    )\n",
    "    data[\"Title\"] = data[\"Title\"].replace(\n",
    "        [\"Dr\", \"Col\", \"Major\", \"Jonkheer\", \"Capt\", \"Sir\", \"Don\", \"Rev\"], \"Dr/Military/Noble/Clergy\"\n",
    "    )\n",
    "    \n",
    "    # 4. Family（姓）\n",
    "    data[\"Family\"] = extract_surname(data[\"Name\"])\n",
    "    \n",
    "    # 5. Family_Size\n",
    "    data[\"Family_Size\"] = data[\"SibSp\"] + data[\"Parch\"] + 1\n",
    "    \n",
    "    # 6. Family_Size_Grouped\n",
    "    family_map = {\n",
    "        1: \"Alone\",\n",
    "        2: \"Small\", 3: \"Small\", 4: \"Small\",\n",
    "        5: \"Medium\", 6: \"Medium\",\n",
    "        7: \"Large\", 8: \"Large\", 11: \"Large\"\n",
    "    }\n",
    "    data[\"Family_Size_Grouped\"] = data[\"Family_Size\"].map(family_map)\n",
    "    \n",
    "    # 7. Deck\n",
    "    data[\"Deck\"] = data[\"Cabin\"].apply(lambda s: s[0] if pd.notnull(s) else \"M\")\n",
    "    data[\"Deck\"] = data[\"Deck\"].replace([\"A\", \"B\", \"C\"], \"ABC\")\n",
    "    data[\"Deck\"] = data[\"Deck\"].replace([\"D\", \"E\"], \"DE\")\n",
    "    data[\"Deck\"] = data[\"Deck\"].replace([\"F\", \"G\"], \"FG\")\n",
    "    data[\"Deck\"] = data[\"Deck\"].replace([\"T\"], \"M\")\n",
    "    \n",
    "    # 8. Embarked補完\n",
    "    data[\"Embarked\"] = data[\"Embarked\"].fillna(\"S\")\n",
    "    \n",
    "    # 9. Sex x Pclass 交互作用\n",
    "    data[\"Sex_Pclass\"] = data[\"Sex\"] + \"_\" + data[\"Pclass\"].astype(str)\n",
    "    \n",
    "    # Age, Fareは元のまま保持\n",
    "    data[\"Age\"] = pd.to_numeric(data[\"Age\"], errors=\"coerce\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# 基本特徴量作成\n",
    "train_base = create_base_features(df_train)\n",
    "test_base = create_base_features(df_test)\n",
    "\n",
    "print(f\"✅ 基本特徴量作成完了\")\n",
    "print(f\"Train shape: {train_base.shape}\")\n",
    "print(f\"Test shape: {test_base.shape}\")\n",
    "print(f\"Is_Married有効数: {train_base['Is_Married'].sum()}件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相関ヒートマップ用にサンプルデータを準備\n",
    "# 簡易的に全データで統計量を計算（可視化目的のみ）\n",
    "sample_train = train_base.copy()\n",
    "sample_test = test_base.copy()\n",
    "\n",
    "# Age補完\n",
    "age_median = sample_train.groupby([\"Sex\", \"Pclass\"])[\"Age\"].median()\n",
    "for pclass in [1, 2, 3]:\n",
    "    for sex in [\"male\", \"female\"]:\n",
    "        mask_train = (sample_train[\"Age\"].isnull()) & (sample_train[\"Pclass\"] == pclass) & (sample_train[\"Sex\"] == sex)\n",
    "        mask_test = (sample_test[\"Age\"].isnull()) & (sample_test[\"Pclass\"] == pclass) & (sample_test[\"Sex\"] == sex)\n",
    "        if mask_train.any():\n",
    "            sample_train.loc[mask_train, \"Age\"] = age_median.loc[(sex, pclass)]\n",
    "        if mask_test.any():\n",
    "            sample_test.loc[mask_test, \"Age\"] = age_median.loc[(sex, pclass)]\n",
    "\n",
    "# Age_Band\n",
    "sample_train[\"Age_Band_num\"] = pd.cut(sample_train[\"Age\"], bins=[0, 12, 18, 30, 50, 80], labels=[0, 1, 2, 3, 4])\n",
    "sample_test[\"Age_Band_num\"] = pd.cut(sample_test[\"Age\"], bins=[0, 12, 18, 30, 50, 80], labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# Fare補完とバンド化\n",
    "fare_median = sample_train[\"Fare\"].median()\n",
    "sample_train[\"Fare\"] = sample_train[\"Fare\"].fillna(fare_median)\n",
    "sample_test[\"Fare\"] = sample_test[\"Fare\"].fillna(fare_median)\n",
    "\n",
    "fare_quantiles = sample_train[\"Fare\"].quantile([0.25, 0.5, 0.75]).values\n",
    "sample_train[\"Fare_Band_num\"] = pd.cut(\n",
    "    sample_train[\"Fare\"],\n",
    "    bins=[-np.inf] + fare_quantiles.tolist() + [np.inf],\n",
    "    labels=[0, 1, 2, 3]\n",
    ")\n",
    "sample_test[\"Fare_Band_num\"] = pd.cut(\n",
    "    sample_test[\"Fare\"],\n",
    "    bins=[-np.inf] + fare_quantiles.tolist() + [np.inf],\n",
    "    labels=[0, 1, 2, 3]\n",
    ")\n",
    "\n",
    "# 数値特徴量のみ選択（相関ヒートマップ用）\n",
    "numeric_features = [\"Is_Married\", \"Family_Size\", \"Age\", \"Fare\", \"Pclass\", \"Age_Band_num\", \"Fare_Band_num\"]\n",
    "X_corr = sample_train[numeric_features].copy()\n",
    "X_corr[\"Perished\"] = sample_train[\"Perished\"]\n",
    "\n",
    "# 相関ヒートマップ\n",
    "corr = X_corr.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,          # 数値を表示\n",
    "    fmt=\".2f\",           # 小数点2桁\n",
    "    cmap=\"coolwarm\",\n",
    "    square=True,\n",
    "    linewidths=0.5,      # 枠線\n",
    "    cbar=True,           # カラーバー\n",
    "    vmin=-1,             # 最小値\n",
    "    vmax=1               # 最大値\n",
    ")\n",
    "plt.title(\"Feature Correlation Heatmap\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "os.makedirs(\"../output\", exist_ok=True)\n",
    "plt.savefig('../output/correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n相関ヒートマップを保存: ../output/correlation_heatmap.png\")\n",
    "print(f\"\\nTop correlations with Perished:\")\n",
    "perished_corr = corr[\"Perished\"].drop(\"Perished\").sort_values(ascending=False)\n",
    "print(perished_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CatBoostハイパーパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_catboost = {\n",
    "    \"iterations\": 1000,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"depth\": 7,\n",
    "    \"l2_leaf_reg\": 6.0,\n",
    "    \"bagging_temperature\": 0.5,\n",
    "    \"random_strength\": 1.0,\n",
    "    \"rsm\": 0.9,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"Logloss\",\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"verbose\": 0\n",
    "}\n",
    "\n",
    "print(\"ハイパーパラメータ設定完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fold-Safe前処理関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fold_safe_features(train_data, valid_data, test_data):\n",
    "    \"\"\"\n",
    "    Fold-Safe: 各Foldのtrain setのみで統計量を計算\n",
    "    \n",
    "    重要: train_dataはすでにtrain部分のみを含む想定\n",
    "    データリーク防止のため、trainとvalidは事前に分離すること\n",
    "    \"\"\"\n",
    "    # 統計量計算用にtrain部分を使用\n",
    "    train_fold = train_data.copy()\n",
    "    \n",
    "    # 1. Age補完（Fold trainのみの中央値）\n",
    "    fold_age_median = train_fold.groupby([\"Sex\", \"Pclass\"])[\"Age\"].median()\n",
    "    \n",
    "    # train/valid/testそれぞれにAge補完を適用\n",
    "    for data in [train_data, valid_data, test_data]:\n",
    "        for pclass in [1, 2, 3]:\n",
    "            for sex in [\"male\", \"female\"]:\n",
    "                mask = (data[\"Age\"].isnull()) & (data[\"Pclass\"] == pclass) & (data[\"Sex\"] == sex)\n",
    "                if mask.any():\n",
    "                    data.loc[mask, \"Age\"] = fold_age_median.loc[(sex, pclass)]\n",
    "    \n",
    "    # Age_Band\n",
    "    for data in [train_data, valid_data, test_data]:\n",
    "        data[\"Age_Band\"] = pd.cut(data[\"Age\"], bins=[0, 12, 18, 30, 50, 80], \n",
    "                                   labels=[\"Child\", \"Teen\", \"Adult\", \"Middle\", \"Senior\"])\n",
    "    \n",
    "    # 2. Fare補完（Fold trainのみの統計量）\n",
    "    fold_fare_median = train_fold[\"Fare\"].median()\n",
    "    fold_fare_quantiles = train_fold[\"Fare\"].quantile([0.25, 0.5, 0.75]).values\n",
    "    \n",
    "    for data in [train_data, valid_data, test_data]:\n",
    "        data[\"Fare\"] = data[\"Fare\"].fillna(fold_fare_median)\n",
    "        data[\"Fare_Band\"] = pd.cut(\n",
    "            data[\"Fare\"],\n",
    "            bins=[-np.inf] + fold_fare_quantiles.tolist() + [np.inf],\n",
    "            labels=[\"Low\", \"Medium\", \"High\", \"Very_High\"]\n",
    "        )\n",
    "    \n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "\n",
    "def prepare_fold_data(train_data, valid_data, test_data, cat_features):\n",
    "    \"\"\"Fold用のデータを準備（CatBoost用）\"\"\"\n",
    "    feature_cols = [\n",
    "         \"Is_Married\",\n",
    "        \"Embarked\", \"Title\", \"Family_Size_Grouped\", \n",
    "        \"Age_Band\", \"Fare_Band\", \"Sex_Pclass\",\n",
    "        #\"Deck\",\n",
    "        #\"Family_Size\",\n",
    "        \"Age\", \"Fare\", \"Pclass\",\n",
    "        #\"Ticket_Frequency\"\n",
    "    ]\n",
    "    \n",
    "    # データ抽出\n",
    "    X_train = train_data[feature_cols].copy()\n",
    "    y_train = train_data[\"Perished\"].copy()\n",
    "    X_valid = valid_data[feature_cols].copy()\n",
    "    y_valid = valid_data[\"Perished\"].copy()\n",
    "    X_test = test_data[feature_cols].copy()\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test\n",
    "\n",
    "\n",
    "print(\"Fold-Safe関数定義完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CatBoost学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost_fold_safe(train_base, test_base, n_folds=10):\n",
    "    \"\"\"StratifiedKFold + Fold-Safe前処理でCatBoost学習\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    y = train_base[\"Perished\"]\n",
    "    \n",
    "    # OOF予測保存用\n",
    "    oof_proba = np.zeros(len(train_base))\n",
    "    test_proba = np.zeros((len(test_base), n_folds))\n",
    "    \n",
    "    models = []\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    \n",
    "    # 学習曲線保存用\n",
    "    learning_curves = []\n",
    "    \n",
    "    # メトリクス保存用\n",
    "    metrics_history = {\n",
    "        \"train_acc\": [], \"valid_acc\": [],\n",
    "        \"train_logloss\": [], \"valid_logloss\": [],\n",
    "        \"valid_roc_auc\": []\n",
    "    }\n",
    "\n",
    "    cat_features = [\"Embarked\", \"Title\", \"Family_Size_Grouped\", \"Age_Band\", \"Fare_Band\", \"Sex_Pclass\"]\n",
    "    print(\"=\"*60)\n",
    "    print(\"CatBoost Fold-Safe Training\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(train_base, y)):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Fold {fold + 1}/{n_folds}\")\n",
    "        print(f\"  Train: {len(train_idx)} samples, Valid: {len(valid_idx)} samples\")\n",
    "        \n",
    "        # クラス分布確認\n",
    "        train_dist = y.iloc[train_idx].value_counts(normalize=True)\n",
    "        valid_dist = y.iloc[valid_idx].value_counts(normalize=True)\n",
    "        print(f\"  Train distribution: {train_dist[1]:.3f} Perished\")\n",
    "        print(f\"  Valid distribution: {valid_dist[1]:.3f} Perished\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        \n",
    "        # データコピー（重要：train/validを分離してからコピー）\n",
    "        train_fold = train_base.iloc[train_idx].copy()\n",
    "        valid_fold = train_base.iloc[valid_idx].copy()\n",
    "        test_fold = test_base.copy()\n",
    "        \n",
    "        # Fold-Safe特徴量作成\n",
    "        train_fold, valid_fold, test_fold = apply_fold_safe_features(\n",
    "            train_fold, valid_fold, test_fold\n",
    "        )\n",
    "        \n",
    "        # データ準備\n",
    "        X_train, y_train, X_valid, y_valid, X_test = prepare_fold_data(\n",
    "            train_fold, valid_fold, test_fold, cat_features\n",
    "        )\n",
    "        \n",
    "        # CatBoost学習\n",
    "        print(\"\\nTraining CatBoost...\")\n",
    "        train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "        valid_pool = Pool(X_valid, y_valid, cat_features=cat_features)\n",
    "        test_pool = Pool(X_test, cat_features=cat_features)\n",
    "        \n",
    "        model = CatBoostClassifier(**best_params_catboost)\n",
    "        model.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=50, verbose=0)\n",
    "        \n",
    "        # 学習曲線を取得\n",
    "        evals_result = model.get_evals_result()\n",
    "        learning_curves.append(evals_result)\n",
    "        \n",
    "        # 予測\n",
    "        oof_proba[valid_idx] = model.predict_proba(valid_pool)[:, 1]\n",
    "        test_proba[:, fold] = model.predict_proba(test_pool)[:, 1]\n",
    "        models.append(model)\n",
    "        \n",
    "        # メトリクス計算\n",
    "        train_proba = model.predict_proba(train_pool)[:, 1]\n",
    "        valid_proba = model.predict_proba(valid_pool)[:, 1]\n",
    "        \n",
    "        train_acc = accuracy_score(y_train, model.predict(train_pool))\n",
    "        valid_acc = accuracy_score(y_valid, model.predict(valid_pool))\n",
    "        train_logloss = log_loss(y_train, train_proba)\n",
    "        valid_logloss = log_loss(y_valid, valid_proba)\n",
    "        valid_roc_auc = roc_auc_score(y_valid, valid_proba)\n",
    "        \n",
    "        train_scores.append(train_acc)\n",
    "        valid_scores.append(valid_acc)\n",
    "        \n",
    "        metrics_history[\"train_acc\"].append(train_acc)\n",
    "        metrics_history[\"valid_acc\"].append(valid_acc)\n",
    "        metrics_history[\"train_logloss\"].append(train_logloss)\n",
    "        metrics_history[\"valid_logloss\"].append(valid_logloss)\n",
    "        metrics_history[\"valid_roc_auc\"].append(valid_roc_auc)\n",
    "        \n",
    "        print(f\"  Acc: Train {train_acc:.4f} | Valid {valid_acc:.4f} | Gap {train_acc - valid_acc:.4f}\")\n",
    "        print(f\"  Logloss: Train {train_logloss:.4f} | Valid {valid_logloss:.4f}\")\n",
    "        print(f\"  ROC-AUC: Valid {valid_roc_auc:.4f}\")\n",
    "    \n",
    "    # CV結果サマリー\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Cross-Validation Results\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    \n",
    "    train_mean = np.mean(train_scores)\n",
    "    train_std = np.std(train_scores)\n",
    "    valid_mean = np.mean(valid_scores)\n",
    "    valid_std = np.std(valid_scores)\n",
    "    gap = train_mean - valid_mean\n",
    "    \n",
    "    valid_logloss_mean = np.mean(metrics_history[\"valid_logloss\"])\n",
    "    valid_roc_auc_mean = np.mean(metrics_history[\"valid_roc_auc\"])\n",
    "    \n",
    "    print(f\"CatBoost:\")\n",
    "    print(f\"  Accuracy: Train {train_mean:.4f} ± {train_std:.4f} | Valid {valid_mean:.4f} ± {valid_std:.4f} | Gap {gap:.4f}\")\n",
    "    print(f\"  Logloss:  Valid {valid_logloss_mean:.4f}\")\n",
    "    print(f\"  ROC-AUC:  Valid {valid_roc_auc_mean:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"oof_proba\": oof_proba,\n",
    "        \"test_proba\": test_proba.mean(axis=1),\n",
    "        \"models\": models,\n",
    "        \"y\": y,\n",
    "        \"learning_curves\": learning_curves,\n",
    "        \"metrics_history\": metrics_history\n",
    "    }\n",
    "\n",
    "\n",
    "# 学習実行\n",
    "results = train_catboost_fold_safe(train_base, test_base, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. テスト予測と提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト予測\n",
    "test_predictions_proba = results[\"test_proba\"]\n",
    "final_predictions = (test_predictions_proba >= 0.5).astype(int)\n",
    "output_path = \"../output/submission_catboost_only.csv\"\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_base[\"PassengerId\"],\n",
    "    \"Perished\": final_predictions\n",
    "})\n",
    "\n",
    "os.makedirs(\"../output\", exist_ok=True)\n",
    "submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n提出ファイル: {output_path}\")\n",
    "print(f\"\\n予測分布:\")\n",
    "print(f\"  Survived (0): {(final_predictions == 0).sum()} ({(final_predictions == 0).sum() / len(final_predictions) * 100:.1f}%)\")\n",
    "print(f\"  Perished (1): {(final_predictions == 1).sum()} ({(final_predictions == 1).sum() / len(final_predictions) * 100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n最初の10行:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "print(f\"\\nCatBoost OOF Accuracy: {accuracy_score(results['y'], (results['oof_proba'] >= 0.5).astype(int)):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 学習曲線可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習曲線の可視化\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "if \"learning_curves\" in results:\n",
    "    for fold_idx, evals_result in enumerate(results[\"learning_curves\"]):\n",
    "        if \"validation\" in evals_result:\n",
    "            valid_loss = evals_result[\"validation\"][\"Logloss\"]\n",
    "            iterations = range(len(valid_loss))\n",
    "            ax.plot(iterations, valid_loss, alpha=0.6, label=f\"Fold {fold_idx+1}\")\n",
    "\n",
    "ax.set_xlabel(\"Iterations\", fontsize=12)\n",
    "ax.set_ylabel(\"Logloss\", fontsize=12)\n",
    "ax.set_title(\"CatBoost Learning Curves (Validation)\", fontweight=\"bold\", fontsize=14)\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../output/catboost_learning_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"学習曲線を保存: ../output/catboost_learning_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ROC曲線可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC曲線の可視化\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "y = results[\"y\"]\n",
    "fpr, tpr, _ = roc_curve(y, results[\"oof_proba\"])\n",
    "roc_auc = roc_auc_score(y, results[\"oof_proba\"])\n",
    "\n",
    "ax.plot(fpr, tpr, color=\"#e74c3c\", lw=2, label=f\"ROC curve (AUC = {roc_auc:.4f})\")\n",
    "ax.plot([0, 1], [0, 1], color=\"gray\", lw=1, linestyle=\"--\", label=\"Random\")\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel(\"False Positive Rate\", fontsize=11)\n",
    "ax.set_ylabel(\"True Positive Rate\", fontsize=11)\n",
    "ax.set_title(\"CatBoost ROC Curve (OOF)\", fontweight=\"bold\", fontsize=13)\n",
    "ax.legend(loc=\"lower right\", fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../output/catboost_roc_curve.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC曲線を保存: ../output/catboost_roc_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 完了メッセージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"すべての処理が完了しました!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n最終OOFスコア: {accuracy_score(results['y'], (results['oof_proba'] >= 0.5).astype(int)):.4f}\")\n",
    "print(\"手法: CatBoost単体 (閾値0.5)\")\n",
    "\n",
    "print(f\"手法: CatBoost単体 (閾値0.5)\")\n",
    "print(f\"\\n実装済み最適化:\")\n",
    "print(f\"  - Fold-Safe前処理（最重要！）\")\n",
    "print(f\"  - StratifiedKFold (クラスバランス維持)\")\n",
    "print(f\"  - Is_Married修正\")\n",
    "print(f\"  - CatBoost最適化\")\n",
    "print(f\"\\nFold-Safeによる改善:\")\n",
    "print(f\"  - データリーク完全防止\")\n",
    "print(f\"  - OOFスコアの信頼性向上\")\n",
    "print(f\"  - Testスコアとの乖離減少\")\n",
    "print(f\"  - Fold間のブレ安定化\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

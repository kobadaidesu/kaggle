{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WCG (Woman-Child-Group) + KNN Model for Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(train_path='../input/train.csv', test_path='../input/test.csv'):\n",
    "    \"\"\"Load and clean train/test data\"\"\"\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    data = pd.concat([train_data, test_data]).reset_index(drop=True)\n",
    "    \n",
    "    # Clean string columns (trim whitespace and replace empty strings with NaN)\n",
    "    str_cols = data.select_dtypes(include=[\"object\"]).columns\n",
    "    data[str_cols] = (data[str_cols]\n",
    "                      .apply(lambda s: s.str.strip())\n",
    "                      .replace(r\"^\\s*$\", np.nan, regex=True))\n",
    "    \n",
    "    # Convert Perished to Survived if needed (for compatibility)\n",
    "    if \"Perished\" in data.columns and \"Survived\" not in data.columns:\n",
    "        data[\"Survived\"] = 1 - data[\"Perished\"]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_and_clean_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ticket_and_group_features(data):\n",
    "    \"\"\"Create Ticket_id and Group_id features\"\"\"\n",
    "    # Extract surname from Name\n",
    "    data['Surname'] = data['Name'].apply(lambda x: x.split(',')[0])\n",
    "    \n",
    "    # Create Ticket_id: Pclass + Ticket + Fare + Embarked\n",
    "    data['Ticket_id'] = (data['Pclass'].astype(str) + '-' + \n",
    "                         data['Ticket'].str[:-1] + '-' + \n",
    "                         data['Fare'].astype(str) + '-' + \n",
    "                         data['Embarked'].astype(str))\n",
    "    \n",
    "    # Create Group_id: Surname + Ticket_id\n",
    "    data['Group_id'] = data['Surname'] + '-' + data['Ticket_id']\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_title_feature(data):\n",
    "    \"\"\"Create Title feature (man/woman/boy)\"\"\"\n",
    "    data['Title'] = 'man'\n",
    "    data.loc[data.Sex == 'female', 'Title'] = 'woman'\n",
    "    data.loc[data['Name'].str.contains('Master', na=False), 'Title'] = 'boy'\n",
    "    return data\n",
    "\n",
    "def identify_wcg_groups(data):\n",
    "    \"\"\"Identify Woman-Child Groups (WCG)\"\"\"\n",
    "    # Set men to 'noGroup'\n",
    "    data.loc[data.Title == 'man', 'Group_id'] = 'noGroup'\n",
    "    \n",
    "    # Count women and children in each group\n",
    "    data['WC_count'] = data.loc[data.Title != 'man'].groupby('Group_id')['Group_id'].transform('count')\n",
    "    \n",
    "    # Assign 'noGroup' to single passengers\n",
    "    data.loc[data.WC_count <= 1, 'Group_id'] = 'noGroup'\n",
    "    \n",
    "    return data\n",
    "\n",
    "def assign_ungrouped_to_groups(data):\n",
    "    \"\"\"Assign ungrouped women/children to existing groups based on Ticket_id\"\"\"\n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "        if (data.loc[i, 'Title'] != 'man') and (data.loc[i, 'Group_id'] == 'noGroup'):\n",
    "            # Find group with same Ticket_id\n",
    "            same_ticket = data.loc[(data['Ticket_id'] == data.loc[i, 'Ticket_id']) & \n",
    "                                   (data.Title != 'man'), 'Group_id']\n",
    "            if len(same_ticket) > 0:\n",
    "                group = same_ticket.iloc[0]\n",
    "                if group != 'noGroup':\n",
    "                    data.loc[i, 'Group_id'] = group\n",
    "                    count += 1\n",
    "    \n",
    "    print(f'{count} passengers were added to an existing group')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 passengers were added to an existing group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    }
   ],
   "source": [
    "# Apply feature engineering\n",
    "data = create_ticket_and_group_features(data)\n",
    "data = create_title_feature(data)\n",
    "data = identify_wcg_groups(data)\n",
    "data = assign_ungrouped_to_groups(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups found: 80\n",
      "Number of passengers in groups: 230\n"
     ]
    }
   ],
   "source": [
    "# Show group statistics\n",
    "number_of_groups = data.loc[data.Group_id != 'noGroup', 'Group_id'].nunique()\n",
    "number_of_passengers = data.loc[data.Group_id != 'noGroup', 'Group_id'].count()\n",
    "print(f'Number of groups found: {number_of_groups}')\n",
    "print(f'Number of passengers in groups: {number_of_passengers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. WCG Survival Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wcg_survival(data):\n",
    "    \"\"\"Calculate survival rate for each Woman-Child Group\"\"\"\n",
    "    # Calculate mean survival for each group in training data\n",
    "    data['WCSurvived'] = (data.loc[(data.Title != 'man') & (data.Group_id != 'noGroup')]\n",
    "                          .groupby('Group_id')['Survived']\n",
    "                          .transform('mean'))\n",
    "    \n",
    "    # Find test-only groups\n",
    "    test_groups = (set(data[891:1309].Group_id.unique()) - \n",
    "                   set(data[0:891].Group_id.unique()))\n",
    "    \n",
    "    # Assign WCSurvived for test-only groups based on Pclass\n",
    "    data.loc[data.Group_id.isin(test_groups), 'WCSurvived'] = 0\n",
    "    data.loc[(data.Group_id.isin(test_groups)) & (data.Pclass != 3), 'WCSurvived'] = 1\n",
    "    \n",
    "    print('WCSurvived distribution in test data:')\n",
    "    print(data[891:1309].WCSurvived.value_counts().to_string())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WCSurvived distribution in test data:\n",
      "WCSurvived\n",
      "1.00    47\n",
      "0.00    24\n",
      "0.75     2\n",
      "0.50     1\n"
     ]
    }
   ],
   "source": [
    "data = calculate_wcg_survival(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Base Predictions using WCG + Gender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_predictions(data):\n",
    "    \"\"\"Create baseline predictions using WCG + Gender model\"\"\"\n",
    "    # Initialize all predictions to 0 (died)\n",
    "    data.loc[891:1308, 'Predict'] = 0\n",
    "    \n",
    "    # Women survive (Predict=1)\n",
    "    mask_women = (data.index >= 891) & (data.index <= 1308) & (data.Sex == 'female')\n",
    "    data.loc[mask_women, 'Predict'] = 1\n",
    "    \n",
    "    # WCG women with WCSurvived=0 die (Predict=0)\n",
    "    mask_wcg_women_died = (data.index >= 891) & (data.index <= 1308) & \\\n",
    "                          (data.Sex == 'female') & (data['WCSurvived'] == 0)\n",
    "    data.loc[mask_wcg_women_died, 'Predict'] = 0\n",
    "    \n",
    "    # WCG boys with WCSurvived=1 survive (Predict=1)\n",
    "    mask_wcg_boys_survived = (data.index >= 891) & (data.index <= 1308) & \\\n",
    "                             (data.Title == 'boy') & (data['WCSurvived'] == 1)\n",
    "    data.loc[mask_wcg_boys_survived, 'Predict'] = 1\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 boys predicted to survive\n",
      "15 women predicted to die\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_664/3849959107.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  boys_survived = data[891:1309][(data.Title == 'boy') & (data.Predict == 1)]\n",
      "/tmp/ipykernel_664/3849959107.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  women_died = data[891:1309][(data.Title == 'woman') & (data.Predict == 0)]\n"
     ]
    }
   ],
   "source": [
    "data = create_base_predictions(data)\n",
    "\n",
    "# Show predictions summary\n",
    "boys_survived = data[891:1309][(data.Title == 'boy') & (data.Predict == 1)]\n",
    "women_died = data[891:1309][(data.Title == 'woman') & (data.Predict == 0)]\n",
    "print(f'{len(boys_survived)} boys predicted to survive')\n",
    "print(f'{len(women_died)} women predicted to die')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Preparation for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fare_features(data):\n",
    "    \"\"\"Calculate per-person fare (Pfare)\"\"\"\n",
    "    data['Ticket_freq'] = data.groupby('Ticket')['Ticket'].transform('count')\n",
    "    data['Pfare'] = data['Fare'] / data['Ticket_freq']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_fare_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. KNN Model for Adult Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessing_pipeline():\n",
    "    \"\"\"Create sklearn preprocessing pipeline\"\"\"\n",
    "    numerical_cols = ['Pfare']\n",
    "    categorical_cols = ['Pclass', 'Embarked']\n",
    "    \n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer()),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def train_male_knn_model(data, features=['Pfare', 'Pclass', 'Embarked']):\n",
    "    \"\"\"Train KNN ensemble model for adult males\"\"\"\n",
    "    # Isolate adult males (not in WCG)\n",
    "    train_male = data[0:891].loc[(data.Sex == 'male') & (data.WCSurvived.isnull())]\n",
    "    test_male = data[891:1309].loc[(data.Sex == 'male') & (data.WCSurvived.isnull())]\n",
    "    \n",
    "    X_m = train_male[features]\n",
    "    y_m = train_male['Survived']\n",
    "    \n",
    "    # Create ensemble of KNN models\n",
    "    m1 = KNeighborsClassifier(n_neighbors=1)\n",
    "    m2 = KNeighborsClassifier(n_neighbors=3)\n",
    "    m3 = KNeighborsClassifier(n_neighbors=7)\n",
    "    \n",
    "    preprocessor = create_preprocessing_pipeline()\n",
    "    \n",
    "    male_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('voting', VotingClassifier([('m1', m1), ('m2', m2), ('m3', m3)]))\n",
    "    ])\n",
    "    \n",
    "    # Cross-validation\n",
    "    precision = cross_val_score(male_pipeline, X_m, y_m, cv=15, n_jobs=-1, scoring='precision').mean()\n",
    "    recall = cross_val_score(male_pipeline, X_m, y_m, cv=15, n_jobs=-1, scoring='recall').mean()\n",
    "    accuracy = cross_val_score(male_pipeline, X_m, y_m, cv=15, n_jobs=-1).mean()\n",
    "    \n",
    "    print(f'Male model - Precision: {precision:.3f}, Recall: {recall:.3f}, Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Train and predict\n",
    "    male_pipeline.fit(X_m, y_m)\n",
    "    X_test_m = test_male[features]\n",
    "    predictions_m = male_pipeline.predict(X_test_m)\n",
    "    \n",
    "    print(f'{(predictions_m == 1).sum()} adult males predicted to survive')\n",
    "    \n",
    "    return test_male, predictions_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male model - Precision: 0.404, Recall: 0.267, Accuracy: 0.816\n",
      "13 adult males predicted to survive\n"
     ]
    }
   ],
   "source": [
    "test_male, predictions_m = train_male_knn_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. KNN Model for Non-WCG Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_female_knn_model(data, features=['Pfare', 'Pclass', 'Embarked']):\n",
    "    \"\"\"Train KNN ensemble model for non-WCG females\"\"\"\n",
    "    # Isolate non-WCG females\n",
    "    train_female = data[0:891].loc[(data.Sex == 'female') & (data.WCSurvived.isnull())]\n",
    "    test_female = data[891:1309].loc[(data.Sex == 'female') & (data.WCSurvived.isnull())]\n",
    "    \n",
    "    X_f = train_female[features]\n",
    "    y_f = train_female['Survived']\n",
    "    \n",
    "    # Create ensemble of KNN models\n",
    "    f1 = KNeighborsClassifier(n_neighbors=4)\n",
    "    f2 = KNeighborsClassifier(n_neighbors=9)\n",
    "    f3 = KNeighborsClassifier(n_neighbors=11)\n",
    "    \n",
    "    preprocessor = create_preprocessing_pipeline()\n",
    "    \n",
    "    female_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('voting', VotingClassifier([('f1', f1), ('f2', f2), ('f3', f3)]))\n",
    "    ])\n",
    "    \n",
    "    # Custom scorers (predicting death, pos_label=0)\n",
    "    custom_precision = make_scorer(precision_score, pos_label=0, zero_division=0)\n",
    "    custom_recall = make_scorer(recall_score, pos_label=0)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_results = cross_validate(\n",
    "        female_pipeline, X_f, y_f, cv=10,\n",
    "        scoring={'precision': custom_precision, 'recall': custom_recall, 'accuracy': 'accuracy'},\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    print(f'Female model - Precision: {cv_results[\"test_precision\"].mean():.3f}, '\n",
    "          f'Recall: {cv_results[\"test_recall\"].mean():.3f}, '\n",
    "          f'Accuracy: {cv_results[\"test_accuracy\"].mean():.3f}')\n",
    "    \n",
    "    # Train and predict\n",
    "    female_pipeline.fit(X_f, y_f)\n",
    "    X_test_f = test_female[features]\n",
    "    predictions_f = female_pipeline.predict(X_test_f)\n",
    "    \n",
    "    print(f'{(predictions_f == 0).sum()} non-WCG females predicted to die')\n",
    "    \n",
    "    return test_female, predictions_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female model - Precision: 0.583, Recall: 0.267, Accuracy: 0.829\n",
      "7 non-WCG females predicted to die\n"
     ]
    }
   ],
   "source": [
    "test_female, predictions_f = train_female_knn_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Predictions and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_predictions(data, test_male, predictions_m, test_female, predictions_f):\n",
    "    \"\"\"Update predictions with KNN results\"\"\"\n",
    "    # Update male predictions\n",
    "    mask_male = (data.index >= 891) & (data.index <= 1308) & \\\n",
    "                (data.Sex == 'male') & (data.WCSurvived.isnull())\n",
    "    data.loc[mask_male, 'Predict'] = predictions_m\n",
    "    \n",
    "    # Update female predictions\n",
    "    mask_female = (data.index >= 891) & (data.index <= 1308) & \\\n",
    "                  (data.Sex == 'female') & (data.WCSurvived.isnull())\n",
    "    data.loc[mask_female, 'Predict'] = predictions_f\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_submission(data, output_path='../output/knn.csv'):\n",
    "    \"\"\"Save predictions to CSV file in Perished format\"\"\"\n",
    "    # Convert Survived format (Predict) to Perished format\n",
    "    output = pd.DataFrame({\n",
    "        'PassengerId': data[891:1309].PassengerId,\n",
    "        'Perished': (1 - data[891:1309].Predict).astype('int')\n",
    "    })\n",
    "    \n",
    "    # Create output directory if needed\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    output.to_csv(output_path, index=False)\n",
    "    print(f'Submission saved to {output_path}')\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to ../output/knn.csv\n"
     ]
    }
   ],
   "source": [
    "# Create final predictions\n",
    "data = create_final_predictions(data, test_male, predictions_m, test_female, predictions_f)\n",
    "\n",
    "# Save submission\n",
    "output = save_submission(data, '../output/knn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predictions:\n",
      "     PassengerId  Perished\n",
      "891          892         1\n",
      "892          893         0\n",
      "893          894         1\n",
      "894          895         1\n",
      "895          896         0\n",
      "896          897         1\n",
      "897          898         0\n",
      "898          899         1\n",
      "899          900         0\n",
      "900          901         1\n",
      "901          902         1\n",
      "902          903         1\n",
      "903          904         0\n",
      "904          905         1\n",
      "905          906         0\n",
      "906          907         0\n",
      "907          908         1\n",
      "908          909         1\n",
      "909          910         1\n",
      "910          911         0\n"
     ]
    }
   ],
   "source": [
    "# Show sample predictions\n",
    "print('\\nSample predictions:')\n",
    "print(output.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
